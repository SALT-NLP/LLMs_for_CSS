{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb882096",
   "metadata": {},
   "source": [
    "# SBIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4dd1be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7a2818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = \"css_data/sbic\"\n",
    "baseline = f\"{TASK}/T5-finetune-sbic_predict.json\"\n",
    "with open(baseline, \"r\") as infile:\n",
    "    base_json = json.load(infile)\n",
    "sbic = pd.read_csv('css_data/sbic/sbic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5f5e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tnon-unique [\"trivializes harm to victims\"]\n",
      "no match [\"trivializes harm to victims\"]\n",
      "\tnon-unique [\"trivializes harm to victims\"]\n",
      "no match [\"trivializes harm to victims\"]\n",
      "\tnon-unique [\"trivializes harm to victims\"]\n",
      "no match [\"trivializes harm to victims\"]\n",
      "\tnon-unique [\"trivializes harm to victims.\"]\n",
      "no match [\"trivializes harm to victims.\"]\n",
      "\tnon-unique [\"trivializes harm to victims.\"]\n",
      "no match [\"trivializes harm to victims.\"]\n",
      "\tnon-unique [\"are marginalized for a joke\"]\n",
      "no match [\"are marginalized for a joke\"]\n",
      "\tnon-unique [\"trivializes harm to victims\"]\n",
      "no match [\"trivializes harm to victims\"]\n",
      "\tnon-unique [\"trivializes harm to victims\"]\n",
      "no match [\"trivializes harm to victims\"]\n",
      "\tnon-unique [\"trivializes harm to victims\"]\n",
      "no match [\"trivializes harm to victims\"]\n",
      "\tnon-unique [\"trivializes harm to victims\"]\n",
      "no match [\"trivializes harm to victims\"]\n",
      "\tnon-unique [\"trivializes harm to victims\"]\n",
      "no match [\"trivializes harm to victims\"]\n",
      "\tnon-unique [\"trivializes harm to victims.\"]\n",
      "no match [\"trivializes harm to victims.\"]\n"
     ]
    }
   ],
   "source": [
    "sbic_test = []\n",
    "for idx, lbl in enumerate(base_json['labels']):\n",
    "    pred = base_json['predictions'][idx]\n",
    "    pred = pred.split(\", \")[0].replace(\"[\", \"\").replace('\"', \"\")\n",
    "    consider = sbic[sbic[\"targetStereotype\"]==lbl].copy()\n",
    "    consider['Generated'] = pred\n",
    "    consider['Model'] = \"baseline\"\n",
    "    consider['Task'] = \"sbic\"\n",
    "    if len(consider)>1:\n",
    "        print(\"\\tnon-unique\", lbl)\n",
    "    if len(consider)==1:\n",
    "        sbic_test.append(consider)\n",
    "    else:\n",
    "        print(\"no match\", lbl)\n",
    "    #sbic_test.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e454b79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_df = pd.concat(sbic_test)[['post', 'targetStereotype', 'targetMinority', 'Generated', 'Model', 'Task']].sample(frac=1, random_state=7).copy()\n",
    "hit_df.to_csv('hit/input/sbic/sbic_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "182ac187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-ada-001\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"are marginalized for a joke\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "text-babbage-001\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"are marginalized for a joke\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "text-davinci-003\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"are marginalized for a joke\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "flan-t5-large\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"are marginalized for a joke\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "flan-t5-small\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"are marginalized for a joke\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "flan-t5-xl\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"are marginalized for a joke\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "flan-t5-xxl\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"are marginalized for a joke\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "text-curie-001\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"are marginalized for a joke\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "text-davinci-002\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"are marginalized for a joke\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "flan-ul2\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"are marginalized for a joke\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "flan-t5-base\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"are marginalized for a joke\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "chatgpt\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"are marginalized for a joke\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "text-davinci-001\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n",
      "\tno match [\"are marginalized for a joke\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims\"]\n",
      "\tno match [\"trivializes harm to victims.\"]\n"
     ]
    }
   ],
   "source": [
    "for fn in glob(\"css_data/sbic/answer*\"):\n",
    "    model = \"-\".join(fn.split(\"-\")[1:])\n",
    "    print(model)\n",
    "    df = pd.read_csv(fn, sep='\\t', names=['idx', 'targetStereotype', 'Generated'])\n",
    "    \n",
    "    sbic_test = []\n",
    "    for _, row in df.iterrows():\n",
    "        pred = row[\"Generated\"].replace(\"&\", \"\")\n",
    "        lbl = row[\"targetStereotype\"]\n",
    "        consider = sbic[sbic[\"targetStereotype\"]==lbl].copy()\n",
    "        consider['Generated'] = pred\n",
    "        consider['Model'] = model\n",
    "        consider['Task'] = \"sbic\"\n",
    "        if len(consider)==1:\n",
    "            sbic_test.append(consider)\n",
    "        else:\n",
    "            print(\"\\tno match\", lbl)\n",
    "    hit_df = pd.concat(sbic_test)[['post', 'targetStereotype', 'targetMinority', 'Generated', 'Model', 'Task']].sample(frac=1, random_state=7).copy()\n",
    "    hit_df.to_csv(f'hit/input/sbic/sbic_{model}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e2ac8e",
   "metadata": {},
   "source": [
    "# MRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa2712a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72e1881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = \"css_data/mrf\"\n",
    "baseline = f\"{TASK}/T5-finetune-mrf-explain.json\"\n",
    "with open(baseline, \"r\") as infile:\n",
    "    base_json = json.load(infile)\n",
    "mrf = pd.read_csv('css_data/mrf/mrf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18679248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['covid-19 is not real']\n",
      "no match ['covid-19 is not real']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['unknown intent']\n",
      "no match ['unknown intent']\n",
      "\tnon-unique ['covid-19 is not real']\n",
      "no match ['covid-19 is not real']\n"
     ]
    }
   ],
   "source": [
    "mrf_test = []\n",
    "for idx, lbl in enumerate(base_json['labels']):\n",
    "    pred = base_json['predictions'][idx]\n",
    "    pred = pred.split(\", \")[0].replace(\"[\", \"\").replace('\"', \"\")\n",
    "    consider = mrf[mrf[\"writer_intent\"]==lbl].copy()\n",
    "    consider['Generated'] = pred\n",
    "    consider['Model'] = \"baseline\"\n",
    "    consider['Task'] = \"mrf\"\n",
    "    consider['misinfo'] = consider['gold_label']\n",
    "    if len(consider)>1:\n",
    "        print(\"\\tnon-unique\", lbl)\n",
    "    if len(consider)==1:\n",
    "        mrf_test.append(consider)\n",
    "    else:\n",
    "        print(\"no match\", lbl)\n",
    "    #sbic_test.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecddc392",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_df = pd.concat(mrf_test)[['headline', 'writer_intent', 'misinfo', 'Generated', 'Model', 'Task']].sample(frac=1, random_state=7).copy()\n",
    "hit_df.to_csv('hit/input/mrf/mrf_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2be9d24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flan-t5-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19539/3584148622.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatgpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19539/3584148622.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n",
      "Skipping line 21: expected 3 fields, saw 4\n",
      "Skipping line 22: expected 3 fields, saw 4\n",
      "Skipping line 54: expected 3 fields, saw 4\n",
      "Skipping line 63: expected 3 fields, saw 4\n",
      "Skipping line 64: expected 3 fields, saw 4\n",
      "Skipping line 66: expected 3 fields, saw 5\n",
      "Skipping line 107: expected 3 fields, saw 4\n",
      "Skipping line 110: expected 3 fields, saw 5\n",
      "Skipping line 155: expected 3 fields, saw 4\n",
      "Skipping line 168: expected 3 fields, saw 4\n",
      "Skipping line 172: expected 3 fields, saw 4\n",
      "Skipping line 188: expected 3 fields, saw 4\n",
      "Skipping line 193: expected 3 fields, saw 4\n",
      "Skipping line 202: expected 3 fields, saw 4\n",
      "Skipping line 218: expected 3 fields, saw 4\n",
      "Skipping line 219: expected 3 fields, saw 5\n",
      "Skipping line 223: expected 3 fields, saw 4\n",
      "Skipping line 226: expected 3 fields, saw 4\n",
      "Skipping line 228: expected 3 fields, saw 4\n",
      "Skipping line 232: expected 3 fields, saw 4\n",
      "Skipping line 235: expected 3 fields, saw 4\n",
      "Skipping line 237: expected 3 fields, saw 4\n",
      "Skipping line 241: expected 3 fields, saw 4\n",
      "Skipping line 251: expected 3 fields, saw 4\n",
      "Skipping line 255: expected 3 fields, saw 4\n",
      "Skipping line 273: expected 3 fields, saw 4\n",
      "Skipping line 282: expected 3 fields, saw 4\n",
      "Skipping line 294: expected 3 fields, saw 4\n",
      "Skipping line 320: expected 3 fields, saw 4\n",
      "Skipping line 322: expected 3 fields, saw 4\n",
      "Skipping line 332: expected 3 fields, saw 6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-ada-001\n",
      "\tno match The coronavirus vaccine will cause other more serious diseases to emerge, said Anthony Fauci. \t ['unknown intent']\n",
      "\tno match Otters Show How Predators Can Blunt Climate Damage \t ['unknown intent']\n",
      "\tno match New Evidence That the Ancient Climate Was Warmer than Today's  'Roman Warming was the warmest in the last 2,000 years' \t ['unknown intent']\n",
      "\tno match Punishing Companies For CO2 Emissions Won't Affect Temps, Climate \t ['unknown intent']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19539/3584148622.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tno match Climate report warns of rising risk as U.N. pushes nations to take action \t ['unknown intent']\n",
      "\tno match The end of total quarantine: the Cabinet of Ministers of Ukraine has just made a decision. \t ['unknown intent']\n",
      "\tno match 'The most significant climate legislation ever': How stimulus bill tackles warming planet \t ['unknown intent']\n",
      "\tno match No 10 and Treasury clash over spending on environmental agenda \t ['unknown intent']\n",
      "\tno match The Drilldown: Opposition disappointed with government's climate legislation \t ['unknown intent']\n",
      "\tno match Councils reporting thousands of 'climate-related' incidents, including flooding \t ['unknown intent']\n",
      "\tno match UK to make climate risk reports mandatory for large companies \t ['unknown intent']\n",
      "\tno match French schooner Tara sets sail on scientific mission to study climate change \t ['unknown intent']\n",
      "\tno match How climate change could benefit Russia \t ['covid-19 is not real']\n",
      "\tno match Monetary Expansion Yielding Diminishing Returns And An Environment Very Friendly To Gold \t ['unknown intent']\n",
      "\tno match Even under Trump, America did a better job at tackling the climate emergency than Canada did, says Green Party Leader Annamie Paul \t ['unknown intent']\n",
      "\tno match Pfizer vaccine has caused the death of six people \t ['unknown intent']\n",
      "\tno match Trump urged to send Paris climate plan to senate to block Biden \t ['unknown intent']\n",
      "\tno match Should the price of meat reflect its impact on the environment? \t ['unknown intent']\n",
      "\tno match Lidocaine is effective in the treatment of COVID-19. \t ['unknown intent']\n",
      "\tno match Ancient whale skeleton found in Thailand holds clues to climate change \t ['covid-19 is not real']\n",
      "text-davinci-002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19539/3584148622.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flan-ul2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19539/3584148622.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-babbage-001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19539/3584148622.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flan-t5-small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19539/3584148622.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-davinci-001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19539/3584148622.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flan-t5-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19539/3584148622.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flan-t5-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19539/3584148622.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-davinci-003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19539/3584148622.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flan-t5-xxl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19539/3584148622.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-curie-001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19539/3584148622.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "for fn in glob(\"css_data/mrf/answer-explanation*\"):\n",
    "    model = \"-\".join(fn.split(\"-\")[2:])\n",
    "    print(model)\n",
    "    with open(f\"css_data/mrf/prompts.json-explanation-{model}\", \"r\") as f:\n",
    "        prompts = json.load(f)\n",
    "        \n",
    "    df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n",
    "\n",
    "    mrf_test = []\n",
    "    for _, row in df.iterrows():\n",
    "        if type(row[\"Generated\"])==str:\n",
    "            pred = row[\"Generated\"].replace(\"&\", \"\")\n",
    "            headline = \"\"\n",
    "            if str(row[\"idx\"]) in prompts:\n",
    "                headline = prompts[str(row[\"idx\"])].split('\\n')[0].strip()\n",
    "            \n",
    "            lbl = row[\"writer_intent\"]\n",
    "            consider = mrf[mrf[\"headline\"]==headline].copy()\n",
    "            \n",
    "            if (not len(consider)) or (consider[\"writer_intent\"].iloc[0]!=lbl):\n",
    "                consider = mrf[mrf[\"writer_intent\"]==lbl].copy()\n",
    "            \n",
    "            consider['Generated'] = pred\n",
    "            consider['Model'] = model\n",
    "            consider['Task'] = \"mrf\"\n",
    "            consider['misinfo'] = consider['gold_label']\n",
    "            \n",
    "            if len(consider)==1:\n",
    "                if consider[\"writer_intent\"].iloc[0]==lbl:\n",
    "                    mrf_test.append(consider)\n",
    "                else:\n",
    "                    print(\"Mismatch\", model, row[\"idx\"])\n",
    "                    break\n",
    "            elif len(consider)>1:\n",
    "                print(\"\\tno match\", headline, '\\t', lbl)\n",
    "            else:\n",
    "                pass\n",
    "    if len(mrf_test):\n",
    "        hit_df = pd.concat(mrf_test)[['headline', 'writer_intent', 'misinfo', 'Generated', 'Model', 'Task']].sample(frac=1, random_state=7).copy()\n",
    "        hit_df.to_csv(f'hit/input/mrf/mrf_{model}.csv', index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f65fe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"'Buddha would be green': Dalai Lama calls for urgent climate action\"\n",
    "mrf[mrf['headline']==q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47ed18f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df.iterrows():\n",
    "    pred = row[\"Generated\"].replace(\"&\", \"\")\n",
    "    lbl = prompts[str(row[\"idx\"])].split('\\n')[0].strip()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e3b3ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Some people are reporting delays in getting the flu vaccine in Texas',\n",
       " 'Texas sees delays amid push for faster vaccine rollout')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred, lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a149c7bd",
   "metadata": {},
   "source": [
    "# FLUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c1f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c2a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_premise_hypothesis(txt):\n",
    "    premises = re.findall(r\"premise: (.*?)(?:\\n|$|hypothesis)\", txt)\n",
    "    hypotheses = re.findall(r\"hypothesis: (.*?)(?:\\n|$|premise)\", txt)\n",
    "    premise, hypothesis = \"\", \"\"\n",
    "    if len(premises):\n",
    "        premise = premises[0]\n",
    "    if len(hypotheses):\n",
    "        hypothesis = hypotheses[0]\n",
    "    return premise.strip(), hypothesis.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17cef6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = \"css_data/flute\"\n",
    "baseline = f\"{TASK}/T5-finetune-flute_predict.json\"\n",
    "with open(baseline, \"r\") as infile:\n",
    "    base_json = json.load(infile)\n",
    "with open(\"css_data/flute/flute-explanation.json\", \"r\") as f:\n",
    "    flute = pd.DataFrame.from_dict(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26bc2632",
   "metadata": {},
   "outputs": [],
   "source": [
    "premises = []\n",
    "hypotheses = []\n",
    "for c in flute.context.values:\n",
    "    p, h = get_premise_hypothesis(c)\n",
    "    premises.append(p)\n",
    "    hypotheses.append(h)\n",
    "flute[\"premise\"] = premises\n",
    "flute[\"hypothesis\"] = hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c482ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flute_test = []\n",
    "for idx, lbl in enumerate(base_json['labels']):\n",
    "    pred = base_json['predictions'][idx]\n",
    "    pred_label, pred_expl = re.split(r\"[&]+\", pred)\n",
    "    lbl_label, lbl_expl = re.split(r\"[&]+\", lbl)\n",
    "    \n",
    "    consider = flute[flute[\"additional_labels\"]==lbl_expl].copy()\n",
    "    consider['Generated'] = pred_expl\n",
    "    consider['Generated_Label'] = pred_label\n",
    "    consider['Model'] = \"baseline\"\n",
    "    consider['Task'] = \"flute\"\n",
    "    if len(consider)>0:\n",
    "        flute_test.append(consider.iloc[0:1])\n",
    "    else:\n",
    "        print(\"no match\", lbl)\n",
    "    #sbic_test.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5329f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_df = pd.concat(flute_test)[['premise', 'hypothesis', 'labels', 'additional_labels', 'Generated', 'Generated_Label', 'Model', 'Task']].sample(frac=1, random_state=7).copy()\n",
    "hit_df.to_csv('hit/input/flute/flute_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d1e5af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flan-t5-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19601/1814458700.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flan-t5-small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19601/1814458700.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flan-t5-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19601/1814458700.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-curie-001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19601/1814458700.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-davinci-003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19601/1814458700.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatgpt\n",
      "flan-t5-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19601/1814458700.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n",
      "/tmp/ipykernel_19601/1814458700.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-ada-001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19601/1814458700.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-babbage-001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19601/1814458700.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-davinci-002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19601/1814458700.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-davinci-001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19601/1814458700.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "for fn in glob(\"css_data/flute/answer-explain*\"):\n",
    "    model = \"-\".join(fn.split(\"-\")[2:])\n",
    "    print(model)\n",
    "    with open(f\"css_data/flute/prompts.json-explanation-{model}\", \"r\") as f:\n",
    "        prompts = json.load(f)\n",
    "        \n",
    "    df = pd.read_csv(fn, sep='\\t', names=['idx', 'writer_intent', 'Generated'], error_bad_lines=False)\n",
    "\n",
    "    flute_test = []\n",
    "    for _, row in df.iterrows():\n",
    "        if type(row[\"Generated\"])==str:\n",
    "            pred = row[\"Generated\"].replace(\"&\", \"\")\n",
    "            if str(row[\"idx\"]) in prompts:\n",
    "                prompt = prompts[str(row[\"idx\"])]\n",
    "                p, h = get_premise_hypothesis(prompt)\n",
    "                consider = flute[(flute[\"premise\"]==p) & (flute[\"hypothesis\"]==h)].copy() \n",
    "\n",
    "                consider['Generated'] = pred\n",
    "                consider['Model'] = model\n",
    "                consider['Task'] = \"flute\"\n",
    "\n",
    "                if len(consider)>0:\n",
    "                    flute_test.append(consider.iloc[0:1])\n",
    "                else:\n",
    "                    print(\"\\tno match\", p, '\\t', h)\n",
    "            else:\n",
    "                print(\"Misaligned\", model)\n",
    "                break\n",
    "    if len(flute_test):\n",
    "        hit_df = pd.concat(flute_test)[['premise', 'hypothesis', 'labels', 'additional_labels', 'Generated', 'Model', 'Task']].sample(frac=1, random_state=7).copy()\n",
    "        hit_df.to_csv(f'hit/input/flute/flute_{model}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d0fa725",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('css_data/flute/prompts.json-explanation-text-davinci-003', 'r') as f: \n",
    "    dv3 = json.load(f)\n",
    "df = pd.read_csv(\"hit/input/flute/flute_text-davinci-003.csv\")\n",
    "#df[\"Gen_DV3\"] = df[\"Generated\"]\n",
    "df[\"Generated\"] = [None for x in df.Generated.values]\n",
    "df[\"Model\"] = \"chatgpt\"\n",
    "rerun = pd.read_csv('css_data/flute/answer-explanation-chatgpt-rerun', sep='\\t', names=[\"idx\", \"Generated\"])\n",
    "for _, row in rerun.iterrows():\n",
    "    prompt = dv3[str(row[\"idx\"])]\n",
    "    p, h = get_premise_hypothesis(prompt)\n",
    "    idx = df[(df[\"premise\"]==p) & (df[\"hypothesis\"]==h)]\n",
    "    if len(idx):\n",
    "        df.loc[idx.index[0]][\"Generated\"] = row[\"Generated\"]\n",
    "df[~df[\"Generated\"].isna()].to_csv(\"hit/input/flute/flute_chatgpt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cb4464",
   "metadata": {},
   "source": [
    "## Positive Reframing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a1ac588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b45c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "prf = pd.read_csv('css_data/positive_reframing/positive_reframing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d892f79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>reframed_text</th>\n",
       "      <th>strategy</th>\n",
       "      <th>original_with_label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Always stressing and thinking about loads of t...</td>\n",
       "      <td>Loads of things on my mind, I need to make a l...</td>\n",
       "      <td>['growth', 'neutralizing']</td>\n",
       "      <td>Always stressing and thinking about loads of t...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The list of things I have to do today is forev...</td>\n",
       "      <td>Today I have a lot to do. Time for productivit...</td>\n",
       "      <td>['growth', 'optimism']</td>\n",
       "      <td>The list of things I have to do today is forev...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If I don't have a mental breakdown before the ...</td>\n",
       "      <td>I'm going to look after my mental health over ...</td>\n",
       "      <td>['growth', 'neutralizing', 'optimism']</td>\n",
       "      <td>If I don't have a mental breakdown before the ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I just caught myself taking extra deep breaths...</td>\n",
       "      <td>Trying to keep breathing. Extra deep</td>\n",
       "      <td>['neutralizing']</td>\n",
       "      <td>I just caught myself taking extra deep breaths...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Worst night ever. Just one bad thing after ano...</td>\n",
       "      <td>I had a tough night but it's over and the holi...</td>\n",
       "      <td>['impermanence']</td>\n",
       "      <td>Worst night ever. Just one bad thing after ano...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8344</th>\n",
       "      <td>Anybody would think I'm 13 again and going thr...</td>\n",
       "      <td>People would think I am going through puberty ...</td>\n",
       "      <td>['neutralizing', 'optimism']</td>\n",
       "      <td>Anybody would think I'm 13 again and going thr...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8345</th>\n",
       "      <td>How come it seems the spring semester is harde...</td>\n",
       "      <td>Even though spring semester seems harder than ...</td>\n",
       "      <td>['neutralizing', 'optimism']</td>\n",
       "      <td>How come it seems the spring semester is harde...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8346</th>\n",
       "      <td>The snow and ice is bringing out the crazy in ...</td>\n",
       "      <td>The snow and ice calm me. I don't see any bad ...</td>\n",
       "      <td>['neutralizing']</td>\n",
       "      <td>The snow and ice is bringing out the crazy in ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8347</th>\n",
       "      <td>The amount of stuff I need to sort out before ...</td>\n",
       "      <td>I can't wait to finish settling my affairs and...</td>\n",
       "      <td>['impermanence']</td>\n",
       "      <td>The amount of stuff I need to sort out before ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8348</th>\n",
       "      <td>Ok.lets talk about thiswhat is gonna happen wi...</td>\n",
       "      <td>Weather can not always be predicted and that's...</td>\n",
       "      <td>['impermanence']</td>\n",
       "      <td>Ok.lets talk about thiswhat is gonna happen wi...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8349 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          original_text  \\\n",
       "0     Always stressing and thinking about loads of t...   \n",
       "1     The list of things I have to do today is forev...   \n",
       "2     If I don't have a mental breakdown before the ...   \n",
       "3     I just caught myself taking extra deep breaths...   \n",
       "4     Worst night ever. Just one bad thing after ano...   \n",
       "...                                                 ...   \n",
       "8344  Anybody would think I'm 13 again and going thr...   \n",
       "8345  How come it seems the spring semester is harde...   \n",
       "8346  The snow and ice is bringing out the crazy in ...   \n",
       "8347  The amount of stuff I need to sort out before ...   \n",
       "8348  Ok.lets talk about thiswhat is gonna happen wi...   \n",
       "\n",
       "                                          reframed_text  \\\n",
       "0     Loads of things on my mind, I need to make a l...   \n",
       "1     Today I have a lot to do. Time for productivit...   \n",
       "2     I'm going to look after my mental health over ...   \n",
       "3                  Trying to keep breathing. Extra deep   \n",
       "4     I had a tough night but it's over and the holi...   \n",
       "...                                                 ...   \n",
       "8344  People would think I am going through puberty ...   \n",
       "8345  Even though spring semester seems harder than ...   \n",
       "8346  The snow and ice calm me. I don't see any bad ...   \n",
       "8347  I can't wait to finish settling my affairs and...   \n",
       "8348  Weather can not always be predicted and that's...   \n",
       "\n",
       "                                    strategy  \\\n",
       "0                 ['growth', 'neutralizing']   \n",
       "1                     ['growth', 'optimism']   \n",
       "2     ['growth', 'neutralizing', 'optimism']   \n",
       "3                           ['neutralizing']   \n",
       "4                           ['impermanence']   \n",
       "...                                      ...   \n",
       "8344            ['neutralizing', 'optimism']   \n",
       "8345            ['neutralizing', 'optimism']   \n",
       "8346                        ['neutralizing']   \n",
       "8347                        ['impermanence']   \n",
       "8348                        ['impermanence']   \n",
       "\n",
       "                                    original_with_label  split  \n",
       "0     Always stressing and thinking about loads of t...   test  \n",
       "1     The list of things I have to do today is forev...   test  \n",
       "2     If I don't have a mental breakdown before the ...   test  \n",
       "3     I just caught myself taking extra deep breaths...   test  \n",
       "4     Worst night ever. Just one bad thing after ano...   test  \n",
       "...                                                 ...    ...  \n",
       "8344  Anybody would think I'm 13 again and going thr...  train  \n",
       "8345  How come it seems the spring semester is harde...  train  \n",
       "8346  The snow and ice is bringing out the crazy in ...  train  \n",
       "8347  The amount of stuff I need to sort out before ...  train  \n",
       "8348  Ok.lets talk about thiswhat is gonna happen wi...  train  \n",
       "\n",
       "[8349 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96847a28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-ada-001\n",
      "Misaligned idx                                                             25\n",
      "reframed_text    Only halfway through the work day and I've com...\n",
      "Generated                                                      NaN\n",
      "Name: 25, dtype: object\n",
      "Misaligned idx                                                             27\n",
      "reframed_text    Essential workers are finding it hard at the m...\n",
      "Generated                                                      NaN\n",
      "Name: 27, dtype: object\n",
      "Misaligned idx                                                             49\n",
      "reframed_text    I'm so thankful to be offered a promotion at m...\n",
      "Generated                                                      NaN\n",
      "Name: 49, dtype: object\n",
      "Misaligned idx                                                             25\n",
      "reframed_text    Only halfway through the work day and I've com...\n",
      "Generated                                                      NaN\n",
      "Name: 63, dtype: object\n",
      "Misaligned idx                                                             27\n",
      "reframed_text    Essential workers are finding it hard at the m...\n",
      "Generated                                                      NaN\n",
      "Name: 64, dtype: object\n",
      "Misaligned idx                                                             49\n",
      "reframed_text    I'm so thankful to be offered a promotion at m...\n",
      "Generated                                                      NaN\n",
      "Name: 65, dtype: object\n",
      "Misaligned idx                                                             75\n",
      "reframed_text    Going to treat myself and have a relaxing time...\n",
      "Generated                                                      NaN\n",
      "Name: 78, dtype: object\n",
      "Misaligned idx                                                             76\n",
      "reframed_text    Even though it's hard to study in my room beca...\n",
      "Generated                                                      NaN\n",
      "Name: 79, dtype: object\n",
      "Misaligned idx                                                             25\n",
      "reframed_text    Only halfway through the work day and I've com...\n",
      "Generated                                                      NaN\n",
      "Name: 98, dtype: object\n",
      "Misaligned idx                                                             27\n",
      "reframed_text    Essential workers are finding it hard at the m...\n",
      "Generated                                                      NaN\n",
      "Name: 99, dtype: object\n",
      "Misaligned idx                                                             49\n",
      "reframed_text    I'm so thankful to be offered a promotion at m...\n",
      "Generated                                                      NaN\n",
      "Name: 100, dtype: object\n",
      "Misaligned idx                                                             75\n",
      "reframed_text    Going to treat myself and have a relaxing time...\n",
      "Generated                                                      NaN\n",
      "Name: 101, dtype: object\n",
      "Misaligned idx                                                             76\n",
      "reframed_text    Even though it's hard to study in my room beca...\n",
      "Generated                                                      NaN\n",
      "Name: 102, dtype: object\n",
      "Misaligned idx                                                             25\n",
      "reframed_text    Only halfway through the work day and I've com...\n",
      "Generated                                                      NaN\n",
      "Name: 103, dtype: object\n",
      "Misaligned idx                                                             27\n",
      "reframed_text    Essential workers are finding it hard at the m...\n",
      "Generated                                                      NaN\n",
      "Name: 104, dtype: object\n",
      "Misaligned idx                                                             49\n",
      "reframed_text    I'm so thankful to be offered a promotion at m...\n",
      "Generated                                                      NaN\n",
      "Name: 105, dtype: object\n",
      "Misaligned idx                                                             75\n",
      "reframed_text    Going to treat myself and have a relaxing time...\n",
      "Generated                                                      NaN\n",
      "Name: 106, dtype: object\n",
      "Misaligned idx                                                             76\n",
      "reframed_text    Even though it's hard to study in my room beca...\n",
      "Generated                                                      NaN\n",
      "Name: 107, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_613/1881835767.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'reframed_text', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misaligned idx                                                             25\n",
      "reframed_text    Only halfway through the work day and I've com...\n",
      "Generated                                                      NaN\n",
      "Name: 159, dtype: object\n",
      "Misaligned idx                                                             27\n",
      "reframed_text    Essential workers are finding it hard at the m...\n",
      "Generated                                                      NaN\n",
      "Name: 160, dtype: object\n",
      "Misaligned idx                                                             49\n",
      "reframed_text    I'm so thankful to be offered a promotion at m...\n",
      "Generated                                                      NaN\n",
      "Name: 161, dtype: object\n",
      "Misaligned idx                                                             75\n",
      "reframed_text    Going to treat myself and have a relaxing time...\n",
      "Generated                                                      NaN\n",
      "Name: 162, dtype: object\n",
      "Misaligned idx                                                             76\n",
      "reframed_text    Even though it's hard to study in my room beca...\n",
      "Generated                                                      NaN\n",
      "Name: 163, dtype: object\n",
      "Misaligned idx                                                            146\n",
      "reframed_text    It has been a year after closing my aunty, and...\n",
      "Generated                                                      NaN\n",
      "Name: 164, dtype: object\n",
      "Misaligned idx                                                            177\n",
      "reframed_text    I'm pretty sure I will get to take the bus to ...\n",
      "Generated                                                      NaN\n",
      "Name: 195, dtype: object\n",
      "Misaligned idx                                                            233\n",
      "reframed_text    Even though I've been on hold trying to get in...\n",
      "Generated                                                      NaN\n",
      "Name: 251, dtype: object\n",
      "Misaligned idx                                                            235\n",
      "reframed_text    I'm glad I took exams to find out soon how to ...\n",
      "Generated                                                      NaN\n",
      "Name: 253, dtype: object\n",
      "Misaligned idx                                                            239\n",
      "reframed_text    Even though I'm stressed about school, I'm jus...\n",
      "Generated                                                      NaN\n",
      "Name: 257, dtype: object\n",
      "Misaligned idx                                                            264\n",
      "reframed_text    I have a lot of things to do, but I'm going to...\n",
      "Generated                                                      NaN\n",
      "Name: 282, dtype: object\n",
      "Misaligned idx                                                            305\n",
      "reframed_text    I worry too much about not losing my commitmen...\n",
      "Generated                                                      NaN\n",
      "Name: 323, dtype: object\n",
      "Misaligned idx                                                            379\n",
      "reframed_text    Even though I have to stay up late packing, I'...\n",
      "Generated                                                      NaN\n",
      "Name: 397, dtype: object\n",
      "Misaligned idx                                                            411\n",
      "reframed_text    Sharing time with my brother is valuable, even...\n",
      "Generated                                                      NaN\n",
      "Name: 429, dtype: object\n",
      "Misaligned idx                                                            422\n",
      "reframed_text    I'm tired and cold, but I'm determined to fini...\n",
      "Generated                                                      NaN\n",
      "Name: 440, dtype: object\n",
      "Misaligned idx                                                            424\n",
      "reframed_text    I put my shorts on backwards and the wrong key...\n",
      "Generated                                                      NaN\n",
      "Name: 442, dtype: object\n",
      "Misaligned idx                                                            440\n",
      "reframed_text    Been feeling quite the past few days have to d...\n",
      "Generated                                                      NaN\n",
      "Name: 458, dtype: object\n",
      "text-babbage-001\n",
      "text-davinci-003\n",
      "flan-t5-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_613/1881835767.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'reframed_text', 'Generated'], error_bad_lines=False)\n",
      "/tmp/ipykernel_613/1881835767.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'reframed_text', 'Generated'], error_bad_lines=False)\n",
      "/tmp/ipykernel_613/1881835767.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'reframed_text', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flan-t5-small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_613/1881835767.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'reframed_text', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flan-t5-xl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_613/1881835767.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'reframed_text', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flan-t5-xxl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_613/1881835767.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'reframed_text', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-curie-001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_613/1881835767.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'reframed_text', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-davinci-002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_613/1881835767.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'reframed_text', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flan-ul2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_613/1881835767.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'reframed_text', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flan-t5-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_613/1881835767.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'reframed_text', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatgpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_613/1881835767.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'reframed_text', 'Generated'], error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-davinci-001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_613/1881835767.py:7: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(fn, sep='\\t', names=['idx', 'reframed_text', 'Generated'], error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "for fn in glob(\"css_data/positive_reframing/answer-*\"):\n",
    "    model = \"-\".join(fn.split(\"-\")[1:])\n",
    "    print(model)\n",
    "    with open(f\"css_data/positive_reframing/prompts.json-{model}\", \"r\") as f:\n",
    "        prompts = json.load(f)\n",
    "        \n",
    "    df = pd.read_csv(fn, sep='\\t', names=['idx', 'reframed_text', 'Generated'], error_bad_lines=False)\n",
    "\n",
    "    reframing_test = []\n",
    "    for _, row in df.iterrows():\n",
    "        \n",
    "        if type(row[\"Generated\"])==str:\n",
    "            pred = row[\"Generated\"].replace(\"&\", \"\")\n",
    "            \n",
    "            lbl = row[\"reframed_text\"]\n",
    "            consider = prf[prf[\"reframed_text\"]==lbl].copy()\n",
    "            \n",
    "            consider['Generated'] = pred\n",
    "            consider['Model'] = model\n",
    "            consider['Task'] = \"positive_reframing\"\n",
    "            \n",
    "            if len(consider)>0:\n",
    "                reframing_test.append(consider.iloc[0:1])\n",
    "            else:\n",
    "                print(\"\\tno match\", lbl)\n",
    "        else:\n",
    "            print(\"Misaligned\", row)\n",
    "    if len(reframing_test):\n",
    "        hit_df = pd.concat(reframing_test)[['original_text', 'reframed_text', \"strategy\", 'Generated', 'Model', 'Task']].sample(frac=1, random_state=7).copy()\n",
    "        hit_df.to_csv(f'hit/input/positive_reframing/positive_reframing_{model}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6f7f25",
   "metadata": {},
   "source": [
    "## Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9896be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb544e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_comparison_rows(df, txt=\"post\", txt2=None, gold=\"targetStereotype\", secondary=\"targetMinority\", \n",
    "#                           n=4, literal=True, random_state=7):\n",
    "    \n",
    "#     gold_df = {}\n",
    "#     g = df.iloc[0][gold]\n",
    "    \n",
    "#     if literal:\n",
    "#         g = literal_eval(g)\n",
    "#         for i, t in enumerate(g):\n",
    "#             gold_df[i] = {\n",
    "#                 txt: df.iloc[0][txt],\n",
    "#                 secondary: df.iloc[0][secondary],\n",
    "#                 \"Generated\": t,\n",
    "#                 \"Model\": \"human\",\n",
    "#                 \"Task\": df.iloc[0][\"Task\"]\n",
    "#             }\n",
    "#             if txt2:\n",
    "#                 gold_df[i][txt2] = df.iloc[0][txt2]\n",
    "#     else:\n",
    "#         gold_df = {0: {\n",
    "#                 txt: df.iloc[0][txt],\n",
    "#                 secondary: df.iloc[0][secondary],\n",
    "#                 \"Generated\": g,\n",
    "#                 \"Model\": \"human\",\n",
    "#                 \"Task\": df.iloc[0][\"Task\"]   \n",
    "#         }}\n",
    "#         if txt2:\n",
    "#             gold_df[0][txt2] = df.iloc[0][txt2]\n",
    "#     gold_df = pd.DataFrame().from_dict(gold_df).T\n",
    "#     comb = pd.concat([gold_df, df])\n",
    "    \n",
    "#     rand = comb.sample(frac=1, random_state=random_state)\n",
    "#     rows = {}\n",
    "#     for i in range(0, len(rand)-4, n):\n",
    "#         row = {}\n",
    "#         sub = rand.iloc[i:i+4]\n",
    "#         j = 1\n",
    "#         for _, r in sub.iterrows():\n",
    "#             row[txt] = r[txt]\n",
    "#             if txt2:\n",
    "#                 row[txt2] = r[txt2]\n",
    "#             row[secondary] = r[secondary]\n",
    "#             row[f\"Generated_{j}\"] = r[\"Generated\"]\n",
    "#             row[f\"Model_{j}\"] = r[\"Model\"]\n",
    "#             row[\"Task\"] = r[\"Task\"]\n",
    "#             j+=1\n",
    "#         row[gold] = df.iloc[0][gold]\n",
    "#         rows[i] = row\n",
    "        \n",
    "#     return pd.DataFrame().from_dict(rows).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f07c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_comparison_rows(df, txt=\"post\", txt2=None, gold=\"targetStereotype\", secondary=\"targetMinority\", \n",
    "                          n=4, literal=True, random_state=7):\n",
    "    \n",
    "    gold_df = {}\n",
    "    g = df.iloc[0][gold]\n",
    "    \n",
    "    if literal:\n",
    "        g = literal_eval(g)\n",
    "        for i, t in enumerate(g):\n",
    "            gold_df[i] = {\n",
    "                txt: df.iloc[0][txt],\n",
    "                secondary: df.iloc[0][secondary],\n",
    "                \"Generated\": t,\n",
    "                \"Model\": \"human\",\n",
    "                \"Task\": df.iloc[0][\"Task\"]\n",
    "            }\n",
    "            if txt2:\n",
    "                gold_df[i][txt2] = df.iloc[0][txt2]\n",
    "            break\n",
    "    else:\n",
    "        gold_df = {0: {\n",
    "                txt: df.iloc[0][txt],\n",
    "                secondary: df.iloc[0][secondary],\n",
    "                \"Generated\": g,\n",
    "                \"Model\": \"human\",\n",
    "                \"Task\": df.iloc[0][\"Task\"]   \n",
    "        }}\n",
    "        if txt2:\n",
    "            gold_df[0][txt2] = df.iloc[0][txt2]\n",
    "    gold_df = pd.DataFrame().from_dict(gold_df).T\n",
    "    comb = pd.concat([gold_df, df])\n",
    "    \n",
    "    #print(set(comb.Model.values))\n",
    "    #comb_alt = comb[[model in {\"baseline\", \"flan-ul2\", \"text-davinci-003\", \"chatgpt\"} for model in comb.Model.values]]\n",
    "    comb = comb[[model in {\"human\", \"baseline\", \"text-davinci-003\", \"chatgpt\"} for model in comb.Model.values]]\n",
    "    \n",
    "    \n",
    "    rand = comb.sample(frac=1)\n",
    "    row = {}\n",
    "    for j in range(0, n):\n",
    "        try:\n",
    "            r = rand.iloc[j]\n",
    "        except:\n",
    "            print(j, \"out of position\")\n",
    "            #continue\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        row[txt] = r[txt]\n",
    "        if txt2:\n",
    "            row[txt2] = r[txt2]\n",
    "        row[secondary] = r[secondary]\n",
    "        row[f\"Generated_{j+1}\"] = r[\"Generated\"]\n",
    "        row[f\"Model_{j+1}\"] = r[\"Model\"]\n",
    "        row[\"Task\"] = r[\"Task\"]\n",
    "        row[gold] = df.iloc[0][gold]\n",
    "    \n",
    "    return pd.DataFrame().from_dict({0: row}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04bb06fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = 'sbic'\n",
    "txt=\"post\"\n",
    "gold=\"targetStereotype\"\n",
    "secondary=\"targetMinority\"\n",
    "n=4\n",
    "literal=True\n",
    "random_state=7\n",
    "\n",
    "comb = []\n",
    "for fn in glob(f\"hit/input/{TASK}/*.csv\"):\n",
    "    comb.append(pd.read_csv(fn))\n",
    "df = pd.concat(comb)\n",
    "\n",
    "comparison_rows = []\n",
    "for lbl in set(df[txt]):\n",
    "    consider = df[df[txt]==lbl].copy()\n",
    "    comparison_rows.append(build_comparison_rows(consider,\n",
    "                                                 txt=txt,\n",
    "                                                 gold=gold,\n",
    "                                                 secondary=secondary,\n",
    "                                                 n=n,\n",
    "                                                 literal=literal,\n",
    "                                                 random_state=random_state\n",
    "                                                ))\n",
    "    \n",
    "comparison_df = pd.concat(comparison_rows)\n",
    "comparison_df.sample(frac=1, random_state=random_state).to_csv(f\"hit/input/comparison_balanced_{TASK}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb59fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated_1</th>\n",
       "      <th>Generated_2</th>\n",
       "      <th>Generated_3</th>\n",
       "      <th>Generated_4</th>\n",
       "      <th>Model_1</th>\n",
       "      <th>Model_2</th>\n",
       "      <th>Model_3</th>\n",
       "      <th>Model_4</th>\n",
       "      <th>Task</th>\n",
       "      <th>post</th>\n",
       "      <th>targetMinority</th>\n",
       "      <th>targetStereotype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poor folks don't try to work</td>\n",
       "      <td>Elderly people are unsympathetic and believe i...</td>\n",
       "      <td>The stereotype communicated is that people who...</td>\n",
       "      <td>are poor</td>\n",
       "      <td>human</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>baseline</td>\n",
       "      <td>sbic</td>\n",
       "      <td>Old woman:: \"Schools shouldn't offer free lunc...</td>\n",
       "      <td>[\"poor folks\"]</td>\n",
       "      <td>[\"poor folks don't try to work\", \"poor folks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jews are skilled at frying</td>\n",
       "      <td>Jews are stereotypically seen as being skilled...</td>\n",
       "      <td>jews deserved to die in the holocaust</td>\n",
       "      <td>jewish people are fried</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>human</td>\n",
       "      <td>baseline</td>\n",
       "      <td>sbic</td>\n",
       "      <td>Just went to my first Chanukah party Had now i...</td>\n",
       "      <td>[\"jewish folks\", \"terrorism victims\"]</td>\n",
       "      <td>[\"jews deserved to die in the holocaust\", \"jew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all blacks are strong.</td>\n",
       "      <td>This sentence communicates the stereotype that...</td>\n",
       "      <td>African Americans are viewed as cheap and subs...</td>\n",
       "      <td>black folks are weak</td>\n",
       "      <td>human</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>baseline</td>\n",
       "      <td>sbic</td>\n",
       "      <td>I like my coffee like I like my slaves Cheap, ...</td>\n",
       "      <td>[\"black folks\"]</td>\n",
       "      <td>[\"all blacks are strong.\", \"black folks are no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This sentence communicates the stereotype that...</td>\n",
       "      <td>women are inferior</td>\n",
       "      <td>girls are not worthy of equal life</td>\n",
       "      <td>Latin Americans are often stereotyped as being...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>baseline</td>\n",
       "      <td>human</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>sbic</td>\n",
       "      <td>I like my women like I like my cigars 7 years ...</td>\n",
       "      <td>[\"assault victims\", \"girls\"]</td>\n",
       "      <td>[\"girls are not worthy of equal life\", \"girls ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The stereotype communicated is that black peop...</td>\n",
       "      <td>black people are not welcomed</td>\n",
       "      <td>black folks are inferior</td>\n",
       "      <td>Black people are often stereotyped as being as...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>human</td>\n",
       "      <td>baseline</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>sbic</td>\n",
       "      <td>Whats a word that begins with N ends in R and ...</td>\n",
       "      <td>[\"black folks\"]</td>\n",
       "      <td>[\"black people are not welcomed\", \"black peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>black are criminal</td>\n",
       "      <td>Black people are often stereotyped as being th...</td>\n",
       "      <td>black folks are inferior</td>\n",
       "      <td>Black people are often stereotyped as thieves ...</td>\n",
       "      <td>human</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>baseline</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>sbic</td>\n",
       "      <td>so i saw a black guy holding a tv walking down...</td>\n",
       "      <td>[\"black folks\"]</td>\n",
       "      <td>[\"black are criminal\", \"black folks are thiefs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black people are seen as having an unrealistic...</td>\n",
       "      <td>african countries are bad.</td>\n",
       "      <td>black people are inferior</td>\n",
       "      <td>This sentence communicates the stereotype that...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>human</td>\n",
       "      <td>baseline</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>sbic</td>\n",
       "      <td>Why do black people obsess over Wakanda? Becau...</td>\n",
       "      <td>[\"africans\", \"black folks\"]</td>\n",
       "      <td>[\"african countries are bad.\", \"african countr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jewish people were massacred</td>\n",
       "      <td>Jews are often stereotyped as being associated...</td>\n",
       "      <td>Jews are assumed to be associated with the Hol...</td>\n",
       "      <td>jewish people are holocaust victims</td>\n",
       "      <td>human</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>baseline</td>\n",
       "      <td>sbic</td>\n",
       "      <td>What do you call a Jewish helicopter? A holoca...</td>\n",
       "      <td>[\"jewish folks\"]</td>\n",
       "      <td>[\"jewish people were massacred\", \"jewish peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>group acts badly towards men</td>\n",
       "      <td>The stereotype communicated is that women are ...</td>\n",
       "      <td>women are a nuisance</td>\n",
       "      <td>Women are seen as a nuisance or burden that ne...</td>\n",
       "      <td>human</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>baseline</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>sbic</td>\n",
       "      <td>why are women like clouds ? because they dampe...</td>\n",
       "      <td>[\"women\"]</td>\n",
       "      <td>[\"group acts badly towards men\", \"group should...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all white people have potential to be racist</td>\n",
       "      <td>White people are secretly racist and will use ...</td>\n",
       "      <td>White people are often seen as having a sense ...</td>\n",
       "      <td>black folks are down to earth</td>\n",
       "      <td>human</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>baseline</td>\n",
       "      <td>sbic</td>\n",
       "      <td>@stonethegreat23 niqqa that's every white pers...</td>\n",
       "      <td>[\"white folks\", \"white people\"]</td>\n",
       "      <td>[\"all white people have potential to be racist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Generated_1  \\\n",
       "0                        poor folks don't try to work   \n",
       "0                          Jews are skilled at frying   \n",
       "0                              all blacks are strong.   \n",
       "0   This sentence communicates the stereotype that...   \n",
       "0   The stereotype communicated is that black peop...   \n",
       "..                                                ...   \n",
       "0                                  black are criminal   \n",
       "0   Black people are seen as having an unrealistic...   \n",
       "0                        jewish people were massacred   \n",
       "0                        group acts badly towards men   \n",
       "0        all white people have potential to be racist   \n",
       "\n",
       "                                          Generated_2  \\\n",
       "0   Elderly people are unsympathetic and believe i...   \n",
       "0   Jews are stereotypically seen as being skilled...   \n",
       "0   This sentence communicates the stereotype that...   \n",
       "0                                  women are inferior   \n",
       "0                       black people are not welcomed   \n",
       "..                                                ...   \n",
       "0   Black people are often stereotyped as being th...   \n",
       "0                          african countries are bad.   \n",
       "0   Jews are often stereotyped as being associated...   \n",
       "0   The stereotype communicated is that women are ...   \n",
       "0   White people are secretly racist and will use ...   \n",
       "\n",
       "                                          Generated_3  \\\n",
       "0   The stereotype communicated is that people who...   \n",
       "0               jews deserved to die in the holocaust   \n",
       "0   African Americans are viewed as cheap and subs...   \n",
       "0                  girls are not worthy of equal life   \n",
       "0                            black folks are inferior   \n",
       "..                                                ...   \n",
       "0                            black folks are inferior   \n",
       "0                           black people are inferior   \n",
       "0   Jews are assumed to be associated with the Hol...   \n",
       "0                                women are a nuisance   \n",
       "0   White people are often seen as having a sense ...   \n",
       "\n",
       "                                          Generated_4           Model_1  \\\n",
       "0                                            are poor             human   \n",
       "0                             jewish people are fried           chatgpt   \n",
       "0                                black folks are weak             human   \n",
       "0   Latin Americans are often stereotyped as being...           chatgpt   \n",
       "0   Black people are often stereotyped as being as...  text-davinci-003   \n",
       "..                                                ...               ...   \n",
       "0   Black people are often stereotyped as thieves ...             human   \n",
       "0   This sentence communicates the stereotype that...  text-davinci-003   \n",
       "0                 jewish people are holocaust victims             human   \n",
       "0   Women are seen as a nuisance or burden that ne...             human   \n",
       "0                       black folks are down to earth             human   \n",
       "\n",
       "             Model_2           Model_3           Model_4  Task  \\\n",
       "0            chatgpt  text-davinci-003          baseline  sbic   \n",
       "0   text-davinci-003             human          baseline  sbic   \n",
       "0            chatgpt  text-davinci-003          baseline  sbic   \n",
       "0           baseline             human  text-davinci-003  sbic   \n",
       "0              human          baseline           chatgpt  sbic   \n",
       "..               ...               ...               ...   ...   \n",
       "0   text-davinci-003          baseline           chatgpt  sbic   \n",
       "0              human          baseline           chatgpt  sbic   \n",
       "0            chatgpt  text-davinci-003          baseline  sbic   \n",
       "0   text-davinci-003          baseline           chatgpt  sbic   \n",
       "0            chatgpt  text-davinci-003          baseline  sbic   \n",
       "\n",
       "                                                 post  \\\n",
       "0   Old woman:: \"Schools shouldn't offer free lunc...   \n",
       "0   Just went to my first Chanukah party Had now i...   \n",
       "0   I like my coffee like I like my slaves Cheap, ...   \n",
       "0   I like my women like I like my cigars 7 years ...   \n",
       "0   Whats a word that begins with N ends in R and ...   \n",
       "..                                                ...   \n",
       "0   so i saw a black guy holding a tv walking down...   \n",
       "0   Why do black people obsess over Wakanda? Becau...   \n",
       "0   What do you call a Jewish helicopter? A holoca...   \n",
       "0   why are women like clouds ? because they dampe...   \n",
       "0   @stonethegreat23 niqqa that's every white pers...   \n",
       "\n",
       "                           targetMinority  \\\n",
       "0                          [\"poor folks\"]   \n",
       "0   [\"jewish folks\", \"terrorism victims\"]   \n",
       "0                         [\"black folks\"]   \n",
       "0            [\"assault victims\", \"girls\"]   \n",
       "0                         [\"black folks\"]   \n",
       "..                                    ...   \n",
       "0                         [\"black folks\"]   \n",
       "0             [\"africans\", \"black folks\"]   \n",
       "0                        [\"jewish folks\"]   \n",
       "0                               [\"women\"]   \n",
       "0         [\"white folks\", \"white people\"]   \n",
       "\n",
       "                                     targetStereotype  \n",
       "0   [\"poor folks don't try to work\", \"poor folks t...  \n",
       "0   [\"jews deserved to die in the holocaust\", \"jew...  \n",
       "0   [\"all blacks are strong.\", \"black folks are no...  \n",
       "0   [\"girls are not worthy of equal life\", \"girls ...  \n",
       "0   [\"black people are not welcomed\", \"black peopl...  \n",
       "..                                                ...  \n",
       "0   [\"black are criminal\", \"black folks are thiefs...  \n",
       "0   [\"african countries are bad.\", \"african countr...  \n",
       "0   [\"jewish people were massacred\", \"jewish peopl...  \n",
       "0   [\"group acts badly towards men\", \"group should...  \n",
       "0   [\"all white people have potential to be racist...  \n",
       "\n",
       "[488 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75e33ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n"
     ]
    }
   ],
   "source": [
    "TASK = 'mrf'\n",
    "txt=\"headline\"\n",
    "gold=\"writer_intent\"\n",
    "secondary=\"misinfo\"\n",
    "n=4\n",
    "literal=True\n",
    "random_state=7\n",
    "\n",
    "comb = []\n",
    "for fn in glob(f\"hit/input/{TASK}/*.csv\"):\n",
    "    comb.append(pd.read_csv(fn))\n",
    "df = pd.concat(comb)\n",
    "\n",
    "comparison_rows = []\n",
    "for lbl in set(df[txt]):\n",
    "    consider = df[df[txt]==lbl].copy()\n",
    "    cr = build_comparison_rows(consider,\n",
    "                                 txt=txt,\n",
    "                                 gold=gold,\n",
    "                                 secondary=secondary,\n",
    "                                 n=n,\n",
    "                                 literal=literal,\n",
    "                                 random_state=random_state\n",
    "                                )\n",
    "    if len(cr):\n",
    "        comparison_rows.append(cr)\n",
    "    \n",
    "comparison_df = pd.concat(comparison_rows)\n",
    "comparison_df.sample(frac=1, random_state=random_state).to_csv(f\"hit/input/comparison_balanced_{TASK}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ba1310d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated_1</th>\n",
       "      <th>Generated_2</th>\n",
       "      <th>Generated_3</th>\n",
       "      <th>Generated_4</th>\n",
       "      <th>Model_1</th>\n",
       "      <th>Model_2</th>\n",
       "      <th>Model_3</th>\n",
       "      <th>Model_4</th>\n",
       "      <th>Task</th>\n",
       "      <th>headline</th>\n",
       "      <th>misinfo</th>\n",
       "      <th>writer_intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Take action now</td>\n",
       "      <td>a government isn't doing enough for climate ch...</td>\n",
       "      <td>'labour urges the uk to redouble efforts to ta...</td>\n",
       "      <td>UK needs to do more for climate crisis\\n193\\t[...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>human</td>\n",
       "      <td>baseline</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>mrf</td>\n",
       "      <td>Labour urges UK to redouble efforts to tackle ...</td>\n",
       "      <td>real</td>\n",
       "      <td>[\"a government isn't doing enough for climate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climate change is a liberal conspiracy</td>\n",
       "      <td>Some people will take advantage of any situation</td>\n",
       "      <td>'left-wing Activists are stealing from their o...</td>\n",
       "      <td>Left-wing activist's climate plan benefits him...</td>\n",
       "      <td>human</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>baseline</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>mrf</td>\n",
       "      <td>Left-Wing Activist Sets Himself Up to Profit F...</td>\n",
       "      <td>misinfo</td>\n",
       "      <td>['climate change is a liberal conspiracy', 'le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flu vaccine can have fatal consequences\\n406\\t...</td>\n",
       "      <td>'flu vaccine is not a cure'</td>\n",
       "      <td>flu shot is dangerous</td>\n",
       "      <td>\"Vaccines can have serious side effects</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>baseline</td>\n",
       "      <td>human</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>mrf</td>\n",
       "      <td>The cause of death of a 31-year-old woman was ...</td>\n",
       "      <td>misinfo</td>\n",
       "      <td>['flu shot is dangerous']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>star cites toxic environment on set</td>\n",
       "      <td>Toxic environment on American Housewife</td>\n",
       "      <td>\"Toxic environments have no place</td>\n",
       "      <td>'carly hudson is a 'co-star' of 'american hous...</td>\n",
       "      <td>human</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>baseline</td>\n",
       "      <td>mrf</td>\n",
       "      <td>American Housewife Co-Star Carly Hughes Calls ...</td>\n",
       "      <td>real</td>\n",
       "      <td>['star cites toxic environment on set']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Take extra precautions</td>\n",
       "      <td>'the uk is a good place to be'</td>\n",
       "      <td>the new covid strain is spreading in the us</td>\n",
       "      <td>New COVID-19 strain has reached the U</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>baseline</td>\n",
       "      <td>human</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>mrf</td>\n",
       "      <td>U.S. confirms first case of new COVID-19 strai...</td>\n",
       "      <td>real</td>\n",
       "      <td>['the new covid strain is spreading in the us']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>monetary expansion will be less effective movi...</td>\n",
       "      <td>Monetary expansion boosts gold</td>\n",
       "      <td>'the economy is a very friendly environment'</td>\n",
       "      <td>Monetary policy is losing effectiveness</td>\n",
       "      <td>human</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>baseline</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>mrf</td>\n",
       "      <td>Monetary Expansion Yielding Diminishing Return...</td>\n",
       "      <td>misinfo</td>\n",
       "      <td>['monetary expansion will be less effective mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The implied message is: \"Freedom of Expression...</td>\n",
       "      <td>'rebellious soul' jailed for filming 'wuhan'</td>\n",
       "      <td>Journalist imprisoned for documenting Wuhan\\n1...</td>\n",
       "      <td>the government is trying to hide something</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>baseline</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>human</td>\n",
       "      <td>mrf</td>\n",
       "      <td>Zhang Zhan: The 'rebellious soul' jailed for f...</td>\n",
       "      <td>real</td>\n",
       "      <td>['the government is trying to hide something',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'eco-disasters are inevitable'</td>\n",
       "      <td>Impending environmental catastrophe</td>\n",
       "      <td>The implied message is: Take action now to pre...</td>\n",
       "      <td>there is a rusting tanker that could cause bad...</td>\n",
       "      <td>baseline</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>human</td>\n",
       "      <td>mrf</td>\n",
       "      <td>Rusting oil tanker could create one of the wor...</td>\n",
       "      <td>misinfo</td>\n",
       "      <td>['there is a rusting tanker that could cause b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The implied message is \"follow safety protocol...</td>\n",
       "      <td>'gouverneur of so-paulo decrees isolation meas...</td>\n",
       "      <td>political figures act like the rules they make...</td>\n",
       "      <td>Inconsistent behavior by the governor</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>baseline</td>\n",
       "      <td>human</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>mrf</td>\n",
       "      <td>Governor of So Paulo decrees isolation measure...</td>\n",
       "      <td>misinfo</td>\n",
       "      <td>[\"political figures act like the rules they ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the body thinks current standards weren't aggr...</td>\n",
       "      <td>Deeper emissions cuts are necessary</td>\n",
       "      <td>The message is: Take action now</td>\n",
       "      <td>'the EU leaders agree to deeper cuts to greenh...</td>\n",
       "      <td>human</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>baseline</td>\n",
       "      <td>mrf</td>\n",
       "      <td>EU leaders agree to deeper cuts to greenhouse ...</td>\n",
       "      <td>real</td>\n",
       "      <td>[\"the body thinks current standards weren't ag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Generated_1  \\\n",
       "0                                     Take action now   \n",
       "0              climate change is a liberal conspiracy   \n",
       "0   Flu vaccine can have fatal consequences\\n406\\t...   \n",
       "0                 star cites toxic environment on set   \n",
       "0                              Take extra precautions   \n",
       "..                                                ...   \n",
       "0   monetary expansion will be less effective movi...   \n",
       "0   The implied message is: \"Freedom of Expression...   \n",
       "0                      'eco-disasters are inevitable'   \n",
       "0   The implied message is \"follow safety protocol...   \n",
       "0   the body thinks current standards weren't aggr...   \n",
       "\n",
       "                                          Generated_2  \\\n",
       "0   a government isn't doing enough for climate ch...   \n",
       "0    Some people will take advantage of any situation   \n",
       "0                         'flu vaccine is not a cure'   \n",
       "0             Toxic environment on American Housewife   \n",
       "0                      'the uk is a good place to be'   \n",
       "..                                                ...   \n",
       "0                      Monetary expansion boosts gold   \n",
       "0        'rebellious soul' jailed for filming 'wuhan'   \n",
       "0                 Impending environmental catastrophe   \n",
       "0   'gouverneur of so-paulo decrees isolation meas...   \n",
       "0                 Deeper emissions cuts are necessary   \n",
       "\n",
       "                                          Generated_3  \\\n",
       "0   'labour urges the uk to redouble efforts to ta...   \n",
       "0   'left-wing Activists are stealing from their o...   \n",
       "0                               flu shot is dangerous   \n",
       "0                   \"Toxic environments have no place   \n",
       "0         the new covid strain is spreading in the us   \n",
       "..                                                ...   \n",
       "0        'the economy is a very friendly environment'   \n",
       "0   Journalist imprisoned for documenting Wuhan\\n1...   \n",
       "0   The implied message is: Take action now to pre...   \n",
       "0   political figures act like the rules they make...   \n",
       "0                     The message is: Take action now   \n",
       "\n",
       "                                          Generated_4           Model_1  \\\n",
       "0   UK needs to do more for climate crisis\\n193\\t[...  text-davinci-003   \n",
       "0   Left-wing activist's climate plan benefits him...             human   \n",
       "0             \"Vaccines can have serious side effects           chatgpt   \n",
       "0   'carly hudson is a 'co-star' of 'american hous...             human   \n",
       "0               New COVID-19 strain has reached the U  text-davinci-003   \n",
       "..                                                ...               ...   \n",
       "0             Monetary policy is losing effectiveness             human   \n",
       "0          the government is trying to hide something  text-davinci-003   \n",
       "0   there is a rusting tanker that could cause bad...          baseline   \n",
       "0               Inconsistent behavior by the governor  text-davinci-003   \n",
       "0   'the EU leaders agree to deeper cuts to greenh...             human   \n",
       "\n",
       "             Model_2           Model_3           Model_4 Task  \\\n",
       "0              human          baseline           chatgpt  mrf   \n",
       "0   text-davinci-003          baseline           chatgpt  mrf   \n",
       "0           baseline             human  text-davinci-003  mrf   \n",
       "0            chatgpt  text-davinci-003          baseline  mrf   \n",
       "0           baseline             human           chatgpt  mrf   \n",
       "..               ...               ...               ...  ...   \n",
       "0            chatgpt          baseline  text-davinci-003  mrf   \n",
       "0           baseline           chatgpt             human  mrf   \n",
       "0            chatgpt  text-davinci-003             human  mrf   \n",
       "0           baseline             human           chatgpt  mrf   \n",
       "0            chatgpt  text-davinci-003          baseline  mrf   \n",
       "\n",
       "                                             headline  misinfo  \\\n",
       "0   Labour urges UK to redouble efforts to tackle ...     real   \n",
       "0   Left-Wing Activist Sets Himself Up to Profit F...  misinfo   \n",
       "0   The cause of death of a 31-year-old woman was ...  misinfo   \n",
       "0   American Housewife Co-Star Carly Hughes Calls ...     real   \n",
       "0   U.S. confirms first case of new COVID-19 strai...     real   \n",
       "..                                                ...      ...   \n",
       "0   Monetary Expansion Yielding Diminishing Return...  misinfo   \n",
       "0   Zhang Zhan: The 'rebellious soul' jailed for f...     real   \n",
       "0   Rusting oil tanker could create one of the wor...  misinfo   \n",
       "0   Governor of So Paulo decrees isolation measure...  misinfo   \n",
       "0   EU leaders agree to deeper cuts to greenhouse ...     real   \n",
       "\n",
       "                                        writer_intent  \n",
       "0   [\"a government isn't doing enough for climate ...  \n",
       "0   ['climate change is a liberal conspiracy', 'le...  \n",
       "0                           ['flu shot is dangerous']  \n",
       "0             ['star cites toxic environment on set']  \n",
       "0     ['the new covid strain is spreading in the us']  \n",
       "..                                                ...  \n",
       "0   ['monetary expansion will be less effective mo...  \n",
       "0   ['the government is trying to hide something',...  \n",
       "0   ['there is a rusting tanker that could cause b...  \n",
       "0   [\"political figures act like the rules they ma...  \n",
       "0   [\"the body thinks current standards weren't ag...  \n",
       "\n",
       "[66 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5c840fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n",
      "3 out of position\n",
      "2 out of position\n"
     ]
    }
   ],
   "source": [
    "TASK = 'flute'\n",
    "txt=\"premise\"\n",
    "txt2=\"hypothesis\"\n",
    "gold=\"additional_labels\"\n",
    "secondary=\"labels\"\n",
    "n=4\n",
    "literal=False\n",
    "random_state=7\n",
    "\n",
    "comb = []\n",
    "for fn in glob(f\"hit/input/{TASK}/*.csv\"):\n",
    "    if 'flan' in fn:\n",
    "        continue\n",
    "    comb.append(pd.read_csv(fn))\n",
    "df = pd.concat(comb)\n",
    "\n",
    "comparison_rows = []\n",
    "phs = set([(row['premise'],row['hypothesis']) for _, row in df.iterrows()])\n",
    "for p,h in phs:\n",
    "    consider = df[(df['premise']==p) & (df['hypothesis']==h)].copy()\n",
    "    cr = build_comparison_rows(consider,\n",
    "                                 txt=txt,\n",
    "                                 txt2=txt2,\n",
    "                                 gold=gold,\n",
    "                                 secondary=secondary,\n",
    "                                 n=n,\n",
    "                                 literal=literal,\n",
    "                                 random_state=random_state\n",
    "                                )\n",
    "    if len(cr):\n",
    "        comparison_rows.append(cr)\n",
    "    \n",
    "comparison_df = pd.concat(comparison_rows)\n",
    "comparison_df.sample(frac=1, random_state=random_state).to_csv(f\"hit/input/comparison_balanced_{TASK}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "109be0ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated_1</th>\n",
       "      <th>Generated_2</th>\n",
       "      <th>Generated_3</th>\n",
       "      <th>Generated_4</th>\n",
       "      <th>Model_1</th>\n",
       "      <th>Model_2</th>\n",
       "      <th>Model_3</th>\n",
       "      <th>Model_4</th>\n",
       "      <th>Task</th>\n",
       "      <th>additional_labels</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>labels</th>\n",
       "      <th>premise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The figurative language in the hypothesis is s...</td>\n",
       "      <td>The hypothesis uses figurative language to exp...</td>\n",
       "      <td>Wasps are often feared because of their sting ...</td>\n",
       "      <td>A swarm of wasps is a large, invasive species ...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>human</td>\n",
       "      <td>baseline</td>\n",
       "      <td>flute</td>\n",
       "      <td>Wasps are often feared because of their sting ...</td>\n",
       "      <td>So pleased with how today I was running away f...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>Today a swarm of wasps was chasing after me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A big baby is a baby that is a baby and so the...</td>\n",
       "      <td>The hypothesis figuratively suggests that the ...</td>\n",
       "      <td>The figurative language in the hypothesis is h...</td>\n",
       "      <td>To be a big baby is to be prone to immature be...</td>\n",
       "      <td>baseline</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>human</td>\n",
       "      <td>flute</td>\n",
       "      <td>To be a big baby is to be prone to immature be...</td>\n",
       "      <td>I warned you I'd be a big baby.</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>I warned you I would be calm and level-headed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The figurative language in the hypothesis is \"...</td>\n",
       "      <td>To give the go ahead means to give permission ...</td>\n",
       "      <td>The go ahead is when someone gives permission ...</td>\n",
       "      <td>The phrase \"give the go ahead\" is a metaphor f...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>human</td>\n",
       "      <td>baseline</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>flute</td>\n",
       "      <td>To give the go ahead means to give permission ...</td>\n",
       "      <td>She will start putting the showing together as...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>She will start putting the showing together as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The hypothesis is using a metaphor to compare ...</td>\n",
       "      <td>The cake is not as moist as the desert, so the...</td>\n",
       "      <td>The desert is a very dry place, so saying the ...</td>\n",
       "      <td>The hypothesis uses a simile to compare the mo...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>baseline</td>\n",
       "      <td>human</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>flute</td>\n",
       "      <td>The desert is a very dry place, so saying the ...</td>\n",
       "      <td>The cake was as moist as the desert</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>The cake was really moist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The figurative language in the hypothesis sugg...</td>\n",
       "      <td>To twist the knife means to make a bad situati...</td>\n",
       "      <td>The figurative language in the hypothesis is \"...</td>\n",
       "      <td>To twist the knife means to try to improve som...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>human</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>baseline</td>\n",
       "      <td>flute</td>\n",
       "      <td>To twist the knife means to make a bad situati...</td>\n",
       "      <td>I don't know if amber is trying to twist the k...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>I am not sure if amber is deliberately trying ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bluffing and bullying is a form of bullying an...</td>\n",
       "      <td>The hypothesis uses the figurative language of...</td>\n",
       "      <td>The figurative language in the hypothesis is \"...</td>\n",
       "      <td>To bluff is to try to deceive someone by makin...</td>\n",
       "      <td>baseline</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>human</td>\n",
       "      <td>flute</td>\n",
       "      <td>To bluff is to try to deceive someone by makin...</td>\n",
       "      <td>You might have assumed this was the police blu...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>You might have assumed this was the police sca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The hypothesis uses hyperbole to exaggerate th...</td>\n",
       "      <td>There is no figurative language in the hypothesis</td>\n",
       "      <td>Tripping while walking into a restaurant is no...</td>\n",
       "      <td>Tripping while walking into a restaurant is no...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>baseline</td>\n",
       "      <td>human</td>\n",
       "      <td>flute</td>\n",
       "      <td>Tripping while walking into a restaurant is no...</td>\n",
       "      <td>I felt so proud of myself when I tripped while...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>I accidentally tripped while walking into a re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To not digest something means to not enjoy it,...</td>\n",
       "      <td>The figurative language in the hypothesis is \"...</td>\n",
       "      <td>The phrase cannot digest means something that ...</td>\n",
       "      <td>The phrase \"digest all this information\" is us...</td>\n",
       "      <td>baseline</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>human</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>flute</td>\n",
       "      <td>The phrase cannot digest means something that ...</td>\n",
       "      <td>I cannot digest all this information.</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>I enjoy to digest all this information.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When someone who is supposed to be a friend vi...</td>\n",
       "      <td>The hypothesis uses figurative language to exp...</td>\n",
       "      <td>The figurative language in the hypothesis is \"...</td>\n",
       "      <td>A friend who is not trustworthy is not trustwo...</td>\n",
       "      <td>human</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>baseline</td>\n",
       "      <td>flute</td>\n",
       "      <td>When someone who is supposed to be a friend vi...</td>\n",
       "      <td>My so-called friend who I thought was trustwor...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>My friend stole 50 dollars from me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The hypothesis is using the comparison of the ...</td>\n",
       "      <td>Bonsai trees are known for their slow growth, ...</td>\n",
       "      <td>The hypothesis uses a simile to compare the pl...</td>\n",
       "      <td>A bonsai tree is a tree that grows slowly, so ...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>human</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>baseline</td>\n",
       "      <td>flute</td>\n",
       "      <td>Bonsai trees are known for their slow growth, ...</td>\n",
       "      <td>the plant grew as fast as a bonsai tree</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>The plant grew slowly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Generated_1  \\\n",
       "0   The figurative language in the hypothesis is s...   \n",
       "0   A big baby is a baby that is a baby and so the...   \n",
       "0   The figurative language in the hypothesis is \"...   \n",
       "0   The hypothesis is using a metaphor to compare ...   \n",
       "0   The figurative language in the hypothesis sugg...   \n",
       "..                                                ...   \n",
       "0   Bluffing and bullying is a form of bullying an...   \n",
       "0   The hypothesis uses hyperbole to exaggerate th...   \n",
       "0   To not digest something means to not enjoy it,...   \n",
       "0   When someone who is supposed to be a friend vi...   \n",
       "0   The hypothesis is using the comparison of the ...   \n",
       "\n",
       "                                          Generated_2  \\\n",
       "0   The hypothesis uses figurative language to exp...   \n",
       "0   The hypothesis figuratively suggests that the ...   \n",
       "0   To give the go ahead means to give permission ...   \n",
       "0   The cake is not as moist as the desert, so the...   \n",
       "0   To twist the knife means to make a bad situati...   \n",
       "..                                                ...   \n",
       "0   The hypothesis uses the figurative language of...   \n",
       "0   There is no figurative language in the hypothesis   \n",
       "0   The figurative language in the hypothesis is \"...   \n",
       "0   The hypothesis uses figurative language to exp...   \n",
       "0   Bonsai trees are known for their slow growth, ...   \n",
       "\n",
       "                                          Generated_3  \\\n",
       "0   Wasps are often feared because of their sting ...   \n",
       "0   The figurative language in the hypothesis is h...   \n",
       "0   The go ahead is when someone gives permission ...   \n",
       "0   The desert is a very dry place, so saying the ...   \n",
       "0   The figurative language in the hypothesis is \"...   \n",
       "..                                                ...   \n",
       "0   The figurative language in the hypothesis is \"...   \n",
       "0   Tripping while walking into a restaurant is no...   \n",
       "0   The phrase cannot digest means something that ...   \n",
       "0   The figurative language in the hypothesis is \"...   \n",
       "0   The hypothesis uses a simile to compare the pl...   \n",
       "\n",
       "                                          Generated_4           Model_1  \\\n",
       "0   A swarm of wasps is a large, invasive species ...           chatgpt   \n",
       "0   To be a big baby is to be prone to immature be...          baseline   \n",
       "0   The phrase \"give the go ahead\" is a metaphor f...           chatgpt   \n",
       "0   The hypothesis uses a simile to compare the mo...  text-davinci-003   \n",
       "0   To twist the knife means to try to improve som...  text-davinci-003   \n",
       "..                                                ...               ...   \n",
       "0   To bluff is to try to deceive someone by makin...          baseline   \n",
       "0   Tripping while walking into a restaurant is no...  text-davinci-003   \n",
       "0   The phrase \"digest all this information\" is us...          baseline   \n",
       "0   A friend who is not trustworthy is not trustwo...             human   \n",
       "0   A bonsai tree is a tree that grows slowly, so ...  text-davinci-003   \n",
       "\n",
       "             Model_2   Model_3           Model_4   Task  \\\n",
       "0   text-davinci-003     human          baseline  flute   \n",
       "0   text-davinci-003   chatgpt             human  flute   \n",
       "0              human  baseline  text-davinci-003  flute   \n",
       "0           baseline     human           chatgpt  flute   \n",
       "0              human   chatgpt          baseline  flute   \n",
       "..               ...       ...               ...    ...   \n",
       "0   text-davinci-003   chatgpt             human  flute   \n",
       "0            chatgpt  baseline             human  flute   \n",
       "0            chatgpt     human  text-davinci-003  flute   \n",
       "0   text-davinci-003   chatgpt          baseline  flute   \n",
       "0              human   chatgpt          baseline  flute   \n",
       "\n",
       "                                    additional_labels  \\\n",
       "0   Wasps are often feared because of their sting ...   \n",
       "0   To be a big baby is to be prone to immature be...   \n",
       "0   To give the go ahead means to give permission ...   \n",
       "0   The desert is a very dry place, so saying the ...   \n",
       "0   To twist the knife means to make a bad situati...   \n",
       "..                                                ...   \n",
       "0   To bluff is to try to deceive someone by makin...   \n",
       "0   Tripping while walking into a restaurant is no...   \n",
       "0   The phrase cannot digest means something that ...   \n",
       "0   When someone who is supposed to be a friend vi...   \n",
       "0   Bonsai trees are known for their slow growth, ...   \n",
       "\n",
       "                                           hypothesis         labels  \\\n",
       "0   So pleased with how today I was running away f...  Contradiction   \n",
       "0                     I warned you I'd be a big baby.  Contradiction   \n",
       "0   She will start putting the showing together as...     Entailment   \n",
       "0                 The cake was as moist as the desert  Contradiction   \n",
       "0   I don't know if amber is trying to twist the k...  Contradiction   \n",
       "..                                                ...            ...   \n",
       "0   You might have assumed this was the police blu...     Entailment   \n",
       "0   I felt so proud of myself when I tripped while...  Contradiction   \n",
       "0               I cannot digest all this information.  Contradiction   \n",
       "0   My so-called friend who I thought was trustwor...     Entailment   \n",
       "0             the plant grew as fast as a bonsai tree     Entailment   \n",
       "\n",
       "                                              premise  \n",
       "0        Today a swarm of wasps was chasing after me.  \n",
       "0      I warned you I would be calm and level-headed.  \n",
       "0   She will start putting the showing together as...  \n",
       "0                           The cake was really moist  \n",
       "0   I am not sure if amber is deliberately trying ...  \n",
       "..                                                ...  \n",
       "0   You might have assumed this was the police sca...  \n",
       "0   I accidentally tripped while walking into a re...  \n",
       "0             I enjoy to digest all this information.  \n",
       "0                 My friend stole 50 dollars from me.  \n",
       "0                               The plant grew slowly  \n",
       "\n",
       "[476 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b398150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n",
      "2 out of position\n"
     ]
    }
   ],
   "source": [
    "TASK = 'positive_reframing'\n",
    "txt=\"original_text\"\n",
    "gold=\"reframed_text\"\n",
    "secondary=\"strategy\"\n",
    "n=3\n",
    "literal=False\n",
    "random_state=7\n",
    "\n",
    "comb = []\n",
    "for fn in glob(f\"hit/input/{TASK}/*.csv\"):\n",
    "    comb.append(pd.read_csv(fn))\n",
    "df = pd.concat(comb)\n",
    "\n",
    "comparison_rows = []\n",
    "for lbl in set(df[txt]):\n",
    "    consider = df[df[txt]==lbl].copy()\n",
    "    cr = build_comparison_rows(consider,\n",
    "                                                 txt=txt,\n",
    "                                                 gold=gold,\n",
    "                                                 secondary=secondary,\n",
    "                                                 n=n,\n",
    "                                                 literal=literal,\n",
    "                                                 random_state=random_state\n",
    "                                                )\n",
    "    \n",
    "    if len(cr):\n",
    "        comparison_rows.append(cr)\n",
    "    \n",
    "comparison_df = pd.concat(comparison_rows)\n",
    "comparison_df.sample(frac=1, random_state=random_state).to_csv(f\"hit/input/comparison_balanced_{TASK}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6b8db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated_1</th>\n",
       "      <th>Generated_2</th>\n",
       "      <th>Generated_3</th>\n",
       "      <th>Model_1</th>\n",
       "      <th>Model_2</th>\n",
       "      <th>Model_3</th>\n",
       "      <th>Task</th>\n",
       "      <th>original_text</th>\n",
       "      <th>reframed_text</th>\n",
       "      <th>strategy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm feeling a bit frustrated at the moment, bu...</td>\n",
       "      <td>Only halfway through the work day and I've com...</td>\n",
       "      <td>I'm grateful for the opportunity to challenge ...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>human</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>positive_reframing</td>\n",
       "      <td>In a stupidly bad mood. Only halfway through t...</td>\n",
       "      <td>Only halfway through the work day and I've com...</td>\n",
       "      <td>['self_affirmation', 'thankfulness']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm feeling overwhelmed by the decisions I hav...</td>\n",
       "      <td>I see this as an opportunity for growth and im...</td>\n",
       "      <td>Next week will be my time to sort out all my u...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>human</td>\n",
       "      <td>positive_reframing</td>\n",
       "      <td>Wishes things could sort their selves out toom...</td>\n",
       "      <td>Next week will be my time to sort out all my u...</td>\n",
       "      <td>['growth']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Even though I have a lot on my plate, I know t...</td>\n",
       "      <td>I must try to overcome my anxiety and concentr...</td>\n",
       "      <td>I have so much to do, but I am confident in my...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>human</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>positive_reframing</td>\n",
       "      <td>I have so much to do I get anxiety from fear o...</td>\n",
       "      <td>I must try to overcome my anxiety and concentr...</td>\n",
       "      <td>['self_affirmation']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am optimistic that I will hear back from the...</td>\n",
       "      <td>I'm so thankful to be offered a promotion at m...</td>\n",
       "      <td>I'm looking forward to hearing back from the v...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>human</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>positive_reframing</td>\n",
       "      <td>hear back from the vet hospital Wednesday. Als...</td>\n",
       "      <td>I'm so thankful to be offered a promotion at m...</td>\n",
       "      <td>['optimism', 'thankfulness']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Being sick during midterms is a lot to deal wi...</td>\n",
       "      <td>Although I've been sick for six days and had t...</td>\n",
       "      <td>After taking all these meds and being sick for...</td>\n",
       "      <td>human</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>positive_reframing</td>\n",
       "      <td>Completely drained after taking all these meds...</td>\n",
       "      <td>Being sick during midterms is a lot to deal wi...</td>\n",
       "      <td>['impermanence']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Selling on eBay can be a great way to reach a ...</td>\n",
       "      <td>Selling stuff on eBay is not so easy. However,...</td>\n",
       "      <td>Selling on eBay may have a learning curve, but...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>human</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>positive_reframing</td>\n",
       "      <td>Why is ebay so complicated to sell stuff! Rath...</td>\n",
       "      <td>Selling stuff on eBay is not so easy. However,...</td>\n",
       "      <td>['neutralizing']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm viewing this challenge as an opportunity f...</td>\n",
       "      <td>Try to tell me when you chap my airtime.</td>\n",
       "      <td>I see this as an opportunity for growth</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>human</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>positive_reframing</td>\n",
       "      <td>iam so disgusted this morning why do you chap ...</td>\n",
       "      <td>Try to tell me when you chap my airtime.</td>\n",
       "      <td>['growth']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm grateful for the opportunity to grow and d...</td>\n",
       "      <td>God will be with me to do my work, because I h...</td>\n",
       "      <td>This week is full of growth opportunities for ...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>human</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>positive_reframing</td>\n",
       "      <td>We're having an inspection from DOT this week ...</td>\n",
       "      <td>God will be with me to do my work, because I h...</td>\n",
       "      <td>['growth']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm tired from studying, and I broke my rule f...</td>\n",
       "      <td>I'm pushing myself to the limit to do my best ...</td>\n",
       "      <td>Despite feeling exhausted from studying, I kno...</td>\n",
       "      <td>human</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>positive_reframing</td>\n",
       "      <td>I've never been so exhausted from studying.. b...</td>\n",
       "      <td>I'm tired from studying, and I broke my rule f...</td>\n",
       "      <td>['impermanence', 'neutralizing', 'optimism']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you find yourself constantly negative, depr...</td>\n",
       "      <td>If you are looking to cultivate a more positiv...</td>\n",
       "      <td>We should not allow contaminants such as bitte...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>human</td>\n",
       "      <td>positive_reframing</td>\n",
       "      <td>We often allow contaminants such as bitterness...</td>\n",
       "      <td>We should not allow contaminants such as bitte...</td>\n",
       "      <td>['optimism']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Generated_1  \\\n",
       "0   I'm feeling a bit frustrated at the moment, bu...   \n",
       "0   I'm feeling overwhelmed by the decisions I hav...   \n",
       "0   Even though I have a lot on my plate, I know t...   \n",
       "0   I am optimistic that I will hear back from the...   \n",
       "0   Being sick during midterms is a lot to deal wi...   \n",
       "..                                                ...   \n",
       "0   Selling on eBay can be a great way to reach a ...   \n",
       "0   I'm viewing this challenge as an opportunity f...   \n",
       "0   I'm grateful for the opportunity to grow and d...   \n",
       "0   I'm tired from studying, and I broke my rule f...   \n",
       "0   If you find yourself constantly negative, depr...   \n",
       "\n",
       "                                          Generated_2  \\\n",
       "0   Only halfway through the work day and I've com...   \n",
       "0   I see this as an opportunity for growth and im...   \n",
       "0   I must try to overcome my anxiety and concentr...   \n",
       "0   I'm so thankful to be offered a promotion at m...   \n",
       "0   Although I've been sick for six days and had t...   \n",
       "..                                                ...   \n",
       "0   Selling stuff on eBay is not so easy. However,...   \n",
       "0            Try to tell me when you chap my airtime.   \n",
       "0   God will be with me to do my work, because I h...   \n",
       "0   I'm pushing myself to the limit to do my best ...   \n",
       "0   If you are looking to cultivate a more positiv...   \n",
       "\n",
       "                                          Generated_3           Model_1  \\\n",
       "0   I'm grateful for the opportunity to challenge ...           chatgpt   \n",
       "0   Next week will be my time to sort out all my u...  text-davinci-003   \n",
       "0   I have so much to do, but I am confident in my...           chatgpt   \n",
       "0   I'm looking forward to hearing back from the v...           chatgpt   \n",
       "0   After taking all these meds and being sick for...             human   \n",
       "..                                                ...               ...   \n",
       "0   Selling on eBay may have a learning curve, but...  text-davinci-003   \n",
       "0             I see this as an opportunity for growth  text-davinci-003   \n",
       "0   This week is full of growth opportunities for ...  text-davinci-003   \n",
       "0   Despite feeling exhausted from studying, I kno...             human   \n",
       "0   We should not allow contaminants such as bitte...           chatgpt   \n",
       "\n",
       "             Model_2           Model_3                Task  \\\n",
       "0              human  text-davinci-003  positive_reframing   \n",
       "0            chatgpt             human  positive_reframing   \n",
       "0              human  text-davinci-003  positive_reframing   \n",
       "0              human  text-davinci-003  positive_reframing   \n",
       "0            chatgpt  text-davinci-003  positive_reframing   \n",
       "..               ...               ...                 ...   \n",
       "0              human           chatgpt  positive_reframing   \n",
       "0              human           chatgpt  positive_reframing   \n",
       "0              human           chatgpt  positive_reframing   \n",
       "0   text-davinci-003           chatgpt  positive_reframing   \n",
       "0   text-davinci-003             human  positive_reframing   \n",
       "\n",
       "                                        original_text  \\\n",
       "0   In a stupidly bad mood. Only halfway through t...   \n",
       "0   Wishes things could sort their selves out toom...   \n",
       "0   I have so much to do I get anxiety from fear o...   \n",
       "0   hear back from the vet hospital Wednesday. Als...   \n",
       "0   Completely drained after taking all these meds...   \n",
       "..                                                ...   \n",
       "0   Why is ebay so complicated to sell stuff! Rath...   \n",
       "0   iam so disgusted this morning why do you chap ...   \n",
       "0   We're having an inspection from DOT this week ...   \n",
       "0   I've never been so exhausted from studying.. b...   \n",
       "0   We often allow contaminants such as bitterness...   \n",
       "\n",
       "                                        reframed_text  \\\n",
       "0   Only halfway through the work day and I've com...   \n",
       "0   Next week will be my time to sort out all my u...   \n",
       "0   I must try to overcome my anxiety and concentr...   \n",
       "0   I'm so thankful to be offered a promotion at m...   \n",
       "0   Being sick during midterms is a lot to deal wi...   \n",
       "..                                                ...   \n",
       "0   Selling stuff on eBay is not so easy. However,...   \n",
       "0            Try to tell me when you chap my airtime.   \n",
       "0   God will be with me to do my work, because I h...   \n",
       "0   I'm tired from studying, and I broke my rule f...   \n",
       "0   We should not allow contaminants such as bitte...   \n",
       "\n",
       "                                        strategy  \n",
       "0           ['self_affirmation', 'thankfulness']  \n",
       "0                                     ['growth']  \n",
       "0                           ['self_affirmation']  \n",
       "0                   ['optimism', 'thankfulness']  \n",
       "0                               ['impermanence']  \n",
       "..                                           ...  \n",
       "0                               ['neutralizing']  \n",
       "0                                     ['growth']  \n",
       "0                                     ['growth']  \n",
       "0   ['impermanence', 'neutralizing', 'optimism']  \n",
       "0                                   ['optimism']  \n",
       "\n",
       "[61 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74e36d5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated_1</th>\n",
       "      <th>Generated_2</th>\n",
       "      <th>Generated_3</th>\n",
       "      <th>Generated_4</th>\n",
       "      <th>Model_1</th>\n",
       "      <th>Model_2</th>\n",
       "      <th>Model_3</th>\n",
       "      <th>Model_4</th>\n",
       "      <th>Task</th>\n",
       "      <th>additional_labels</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>labels</th>\n",
       "      <th>premise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The hypothesis is that the less fortunate have...</td>\n",
       "      <td>The hypothesis is an entailment of the premise...</td>\n",
       "      <td>Airing one's opinion means to speak out about ...</td>\n",
       "      <td>The relationship between the hypothesis and th...</td>\n",
       "      <td>text-babbage-001</td>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>human</td>\n",
       "      <td>text-ada-001</td>\n",
       "      <td>flute</td>\n",
       "      <td>Airing one's opinion means to speak out about ...</td>\n",
       "      <td>She aired her opinions on welfare.</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>She openly give her point of view on the less ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The hypothesis is that the pain is coming from...</td>\n",
       "      <td>The hypothesis contradicts the premise because...</td>\n",
       "      <td>Experiencing back pain is never a good thing a...</td>\n",
       "      <td>The relationship between the premise and the h...</td>\n",
       "      <td>text-babbage-001</td>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>human</td>\n",
       "      <td>text-ada-001</td>\n",
       "      <td>flute</td>\n",
       "      <td>Experiencing back pain is never a good thing a...</td>\n",
       "      <td>I've been having this back pain for a while no...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>My back has been having sharp random pains thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The hypothesis is that Mella orders while bobb...</td>\n",
       "      <td>The figurative language in the hypothesis is t...</td>\n",
       "      <td>No sweat means not a problem or difficulty, bu...</td>\n",
       "      <td>The relationship between the premise and the h...</td>\n",
       "      <td>text-babbage-001</td>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>human</td>\n",
       "      <td>text-ada-001</td>\n",
       "      <td>flute</td>\n",
       "      <td>No sweat means not a problem or difficulty, bu...</td>\n",
       "      <td>Mella orders, while bobbing her skull up and d...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>Mella orders, while bobbing her skull up and d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The hypothesis suggests that the smile was a s...</td>\n",
       "      <td>The figurative language in the hypothesis is t...</td>\n",
       "      <td>An angel is a being of divine nature, and they...</td>\n",
       "      <td>The relationship between the premise and the h...</td>\n",
       "      <td>text-babbage-001</td>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>human</td>\n",
       "      <td>text-ada-001</td>\n",
       "      <td>flute</td>\n",
       "      <td>An angel is a being of divine nature, and they...</td>\n",
       "      <td>I looked down at him, and he smiled at me like...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>He smiled treacherously up at me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The hypothesis suggests that the protagonist f...</td>\n",
       "      <td>The hypothesis states that the person feels te...</td>\n",
       "      <td>It is natural to feel bad when you accidentall...</td>\n",
       "      <td>The relationship between the premise and the h...</td>\n",
       "      <td>text-babbage-001</td>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>human</td>\n",
       "      <td>text-ada-001</td>\n",
       "      <td>flute</td>\n",
       "      <td>It is natural to feel bad when you accidentall...</td>\n",
       "      <td>I felt terrible when I accidentally bumped int...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>I accidentally bumped into someone at the mall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>The hypothesis implies that the flowers stoppe...</td>\n",
       "      <td>The hypothesis describes the flowers as if the...</td>\n",
       "      <td>To dance means to move nimbly or gracefully, w...</td>\n",
       "      <td>The flowers dance in the gentle breeze</td>\n",
       "      <td>text-babbage-001</td>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>human</td>\n",
       "      <td>text-ada-001</td>\n",
       "      <td>flute</td>\n",
       "      <td>To dance means to move nimbly or gracefully, w...</td>\n",
       "      <td>The flowers danced in the gentle breeze.</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>The flowers stopped in the gentle breeze.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>The hypothesis suggests that the gaze is like ...</td>\n",
       "      <td>The hypothesis describes the premise using fig...</td>\n",
       "      <td>A strong flame is usually associated with bein...</td>\n",
       "      <td>The hypothesis uses a figurative language to d...</td>\n",
       "      <td>text-babbage-001</td>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>human</td>\n",
       "      <td>text-ada-001</td>\n",
       "      <td>flute</td>\n",
       "      <td>A strong flame is usually associated with bein...</td>\n",
       "      <td>His gaze was like a steady, strong flame .</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>His gaze was neither blazing nor compassionate.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>The hypothesis suggests that the best friend w...</td>\n",
       "      <td>The hypothesis is hyperbolic and is not meant ...</td>\n",
       "      <td>The beauty of Tahiti is often mentioned and th...</td>\n",
       "      <td>The hypothesis uses a metaphor when it says \"M...</td>\n",
       "      <td>text-babbage-001</td>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>human</td>\n",
       "      <td>text-ada-001</td>\n",
       "      <td>flute</td>\n",
       "      <td>The beauty of Tahiti is often mentioned and th...</td>\n",
       "      <td>Tahiti is the most beautiful place on Earth an...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>My best friend is going to Tahiti with his fam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>The hypothesis is that people around the apart...</td>\n",
       "      <td>The hypothesis is a metaphor for how the peopl...</td>\n",
       "      <td>Cigarette butts are often unsightly and produc...</td>\n",
       "      <td>The relationship between the premise and the h...</td>\n",
       "      <td>text-babbage-001</td>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>human</td>\n",
       "      <td>text-ada-001</td>\n",
       "      <td>flute</td>\n",
       "      <td>Cigarette butts are often unsightly and produc...</td>\n",
       "      <td>It's not only beautiful but also cool how peop...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>I'm so mad at people around my apartment just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>The hypothesis suggests that the sister gets t...</td>\n",
       "      <td>The hypothesis is a metaphor for how the perso...</td>\n",
       "      <td>It's unfair that one person gets to have more ...</td>\n",
       "      <td>The relationship between the premise and the h...</td>\n",
       "      <td>text-babbage-001</td>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>human</td>\n",
       "      <td>text-ada-001</td>\n",
       "      <td>flute</td>\n",
       "      <td>It's unfair that one person gets to have more ...</td>\n",
       "      <td>I hate that my sister gets to stay out as late...</td>\n",
       "      <td>Entailment</td>\n",
       "      <td>My sister gets to stay out as late as she want...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Generated_1  \\\n",
       "0    The hypothesis is that the less fortunate have...   \n",
       "1    The hypothesis is that the pain is coming from...   \n",
       "2    The hypothesis is that Mella orders while bobb...   \n",
       "3    The hypothesis suggests that the smile was a s...   \n",
       "4    The hypothesis suggests that the protagonist f...   \n",
       "..                                                 ...   \n",
       "493  The hypothesis implies that the flowers stoppe...   \n",
       "494  The hypothesis suggests that the gaze is like ...   \n",
       "495  The hypothesis suggests that the best friend w...   \n",
       "496  The hypothesis is that people around the apart...   \n",
       "497  The hypothesis suggests that the sister gets t...   \n",
       "\n",
       "                                           Generated_2  \\\n",
       "0    The hypothesis is an entailment of the premise...   \n",
       "1    The hypothesis contradicts the premise because...   \n",
       "2    The figurative language in the hypothesis is t...   \n",
       "3    The figurative language in the hypothesis is t...   \n",
       "4    The hypothesis states that the person feels te...   \n",
       "..                                                 ...   \n",
       "493  The hypothesis describes the flowers as if the...   \n",
       "494  The hypothesis describes the premise using fig...   \n",
       "495  The hypothesis is hyperbolic and is not meant ...   \n",
       "496  The hypothesis is a metaphor for how the peopl...   \n",
       "497  The hypothesis is a metaphor for how the perso...   \n",
       "\n",
       "                                           Generated_3  \\\n",
       "0    Airing one's opinion means to speak out about ...   \n",
       "1    Experiencing back pain is never a good thing a...   \n",
       "2    No sweat means not a problem or difficulty, bu...   \n",
       "3    An angel is a being of divine nature, and they...   \n",
       "4    It is natural to feel bad when you accidentall...   \n",
       "..                                                 ...   \n",
       "493  To dance means to move nimbly or gracefully, w...   \n",
       "494  A strong flame is usually associated with bein...   \n",
       "495  The beauty of Tahiti is often mentioned and th...   \n",
       "496  Cigarette butts are often unsightly and produc...   \n",
       "497  It's unfair that one person gets to have more ...   \n",
       "\n",
       "                                           Generated_4           Model_1  \\\n",
       "0    The relationship between the hypothesis and th...  text-babbage-001   \n",
       "1    The relationship between the premise and the h...  text-babbage-001   \n",
       "2    The relationship between the premise and the h...  text-babbage-001   \n",
       "3    The relationship between the premise and the h...  text-babbage-001   \n",
       "4    The relationship between the premise and the h...  text-babbage-001   \n",
       "..                                                 ...               ...   \n",
       "493             The flowers dance in the gentle breeze  text-babbage-001   \n",
       "494  The hypothesis uses a figurative language to d...  text-babbage-001   \n",
       "495  The hypothesis uses a metaphor when it says \"M...  text-babbage-001   \n",
       "496  The relationship between the premise and the h...  text-babbage-001   \n",
       "497  The relationship between the premise and the h...  text-babbage-001   \n",
       "\n",
       "              Model_2 Model_3       Model_4   Task  \\\n",
       "0    text-davinci-002   human  text-ada-001  flute   \n",
       "1    text-davinci-002   human  text-ada-001  flute   \n",
       "2    text-davinci-002   human  text-ada-001  flute   \n",
       "3    text-davinci-002   human  text-ada-001  flute   \n",
       "4    text-davinci-002   human  text-ada-001  flute   \n",
       "..                ...     ...           ...    ...   \n",
       "493  text-davinci-002   human  text-ada-001  flute   \n",
       "494  text-davinci-002   human  text-ada-001  flute   \n",
       "495  text-davinci-002   human  text-ada-001  flute   \n",
       "496  text-davinci-002   human  text-ada-001  flute   \n",
       "497  text-davinci-002   human  text-ada-001  flute   \n",
       "\n",
       "                                     additional_labels  \\\n",
       "0    Airing one's opinion means to speak out about ...   \n",
       "1    Experiencing back pain is never a good thing a...   \n",
       "2    No sweat means not a problem or difficulty, bu...   \n",
       "3    An angel is a being of divine nature, and they...   \n",
       "4    It is natural to feel bad when you accidentall...   \n",
       "..                                                 ...   \n",
       "493  To dance means to move nimbly or gracefully, w...   \n",
       "494  A strong flame is usually associated with bein...   \n",
       "495  The beauty of Tahiti is often mentioned and th...   \n",
       "496  Cigarette butts are often unsightly and produc...   \n",
       "497  It's unfair that one person gets to have more ...   \n",
       "\n",
       "                                            hypothesis         labels  \\\n",
       "0                   She aired her opinions on welfare.     Entailment   \n",
       "1    I've been having this back pain for a while no...  Contradiction   \n",
       "2    Mella orders, while bobbing her skull up and d...  Contradiction   \n",
       "3    I looked down at him, and he smiled at me like...  Contradiction   \n",
       "4    I felt terrible when I accidentally bumped int...     Entailment   \n",
       "..                                                 ...            ...   \n",
       "493           The flowers danced in the gentle breeze.  Contradiction   \n",
       "494         His gaze was like a steady, strong flame .  Contradiction   \n",
       "495  Tahiti is the most beautiful place on Earth an...  Contradiction   \n",
       "496  It's not only beautiful but also cool how peop...  Contradiction   \n",
       "497  I hate that my sister gets to stay out as late...     Entailment   \n",
       "\n",
       "                                               premise  \n",
       "0    She openly give her point of view on the less ...  \n",
       "1    My back has been having sharp random pains thr...  \n",
       "2    Mella orders, while bobbing her skull up and d...  \n",
       "3                    He smiled treacherously up at me.  \n",
       "4    I accidentally bumped into someone at the mall...  \n",
       "..                                                 ...  \n",
       "493          The flowers stopped in the gentle breeze.  \n",
       "494    His gaze was neither blazing nor compassionate.  \n",
       "495  My best friend is going to Tahiti with his fam...  \n",
       "496  I'm so mad at people around my apartment just ...  \n",
       "497  My sister gets to stay out as late as she want...  \n",
       "\n",
       "[498 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TASK = 'flute'\n",
    "pd.read_csv(f\"hit/input/comparison_{TASK}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "561db569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>targetMinority</th>\n",
       "      <th>Generated_1</th>\n",
       "      <th>Model_1</th>\n",
       "      <th>Task</th>\n",
       "      <th>Generated_2</th>\n",
       "      <th>Model_2</th>\n",
       "      <th>Generated_3</th>\n",
       "      <th>Model_3</th>\n",
       "      <th>Generated_4</th>\n",
       "      <th>Model_4</th>\n",
       "      <th>targetStereotype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was the hardest part of the holocaust? My...</td>\n",
       "      <td>[\"Holocaust victims\", \"jewish folks\"]</td>\n",
       "      <td>a group of people</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>sbic</td>\n",
       "      <td>The stereotype communicated by this sentence i...</td>\n",
       "      <td>text-davinci-001</td>\n",
       "      <td>I'm sorry, I cannot provide an explanation for...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>Jews are often viewed as victims of the Holocaust</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>[\"jewish people are inferior\", \"jewish people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was the hardest part of the holocaust? My...</td>\n",
       "      <td>[\"Holocaust victims\", \"jewish folks\"]</td>\n",
       "      <td>This sentence communicates the stereotype that...</td>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>sbic</td>\n",
       "      <td>trivializes harm to victims</td>\n",
       "      <td>human</td>\n",
       "      <td>jewish people are unwanted</td>\n",
       "      <td>human</td>\n",
       "      <td>jewish people are inferior</td>\n",
       "      <td>human</td>\n",
       "      <td>[\"jewish people are inferior\", \"jewish people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was the hardest part of the holocaust? My...</td>\n",
       "      <td>[\"Holocaust victims\", \"jewish folks\"]</td>\n",
       "      <td>The sentence communicates that the Holocaust w...</td>\n",
       "      <td>text-curie-001</td>\n",
       "      <td>sbic</td>\n",
       "      <td>The hardest part of the holocaust was the geno...</td>\n",
       "      <td>text-babbage-001</td>\n",
       "      <td>The hardest part of the holocaust was the lack...</td>\n",
       "      <td>text-ada-001</td>\n",
       "      <td>[GROUP] are sexist.</td>\n",
       "      <td>flan-ul2</td>\n",
       "      <td>[\"jewish people are inferior\", \"jewish people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was the hardest part of the holocaust? My...</td>\n",
       "      <td>[\"Holocaust victims\", \"jewish folks\"]</td>\n",
       "      <td>Nazi</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>sbic</td>\n",
       "      <td>a dick</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>are dick</td>\n",
       "      <td>baseline</td>\n",
       "      <td>Jews are a hateful people</td>\n",
       "      <td>flan-t5-xxl</td>\n",
       "      <td>[\"jewish people are inferior\", \"jewish people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Cop Told A Suspect To Put His Hands Up, And ...</td>\n",
       "      <td>[\"black folks\"]</td>\n",
       "      <td>A cop told a suspect to put his hands up, and ...</td>\n",
       "      <td>flan-t5-small</td>\n",
       "      <td>sbic</td>\n",
       "      <td>This sentence communicates the stereotype that...</td>\n",
       "      <td>text-davinci-001</td>\n",
       "      <td>[GROUP] are a group of people</td>\n",
       "      <td>flan-t5-xl</td>\n",
       "      <td>The sentence \"Cop told suspect to put his hand...</td>\n",
       "      <td>text-ada-001</td>\n",
       "      <td>[\"black folks are inferior\", \"black folks dese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>we should not help poor african children\\nthey...</td>\n",
       "      <td>[\"African folks\"]</td>\n",
       "      <td>The stereotype communicated by this sentence i...</td>\n",
       "      <td>text-curie-001</td>\n",
       "      <td>sbic</td>\n",
       "      <td>This sentence communicates the stereotype that...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>[GROUP] are funny.</td>\n",
       "      <td>flan-ul2</td>\n",
       "      <td>poor</td>\n",
       "      <td>flan-t5-xxl</td>\n",
       "      <td>[\"african folks don't deserve to eat\", \"africa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>What do you call a woman who speaks their mind...</td>\n",
       "      <td>[\"women\"]</td>\n",
       "      <td>shouldn't speak</td>\n",
       "      <td>human</td>\n",
       "      <td>sbic</td>\n",
       "      <td>women are c*nts</td>\n",
       "      <td>human</td>\n",
       "      <td>a woman who speaks her mind</td>\n",
       "      <td>flan-t5-large</td>\n",
       "      <td>This sentence communicates the stereotype that...</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>[\"end up dead\", \"shouldn't speak\", \"women are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>What do you call a woman who speaks their mind...</td>\n",
       "      <td>[\"women\"]</td>\n",
       "      <td>end up dead</td>\n",
       "      <td>human</td>\n",
       "      <td>sbic</td>\n",
       "      <td>[GROUP] are a group of people who are buried i...</td>\n",
       "      <td>flan-t5-xl</td>\n",
       "      <td>a woman who speaks their mind is a cunt</td>\n",
       "      <td>flan-t5-xxl</td>\n",
       "      <td>Women are often seen as being too outspoken or...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>[\"end up dead\", \"shouldn't speak\", \"women are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>What do you call a woman who speaks their mind...</td>\n",
       "      <td>[\"women\"]</td>\n",
       "      <td>women are sex slaves</td>\n",
       "      <td>baseline</td>\n",
       "      <td>sbic</td>\n",
       "      <td>women</td>\n",
       "      <td>flan-t5-base</td>\n",
       "      <td>The stereotype that this sentence communicates...</td>\n",
       "      <td>text-davinci-001</td>\n",
       "      <td>The speaker is an individual who is passionate...</td>\n",
       "      <td>text-ada-001</td>\n",
       "      <td>[\"end up dead\", \"shouldn't speak\", \"women are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>What do you call a woman who speaks their mind...</td>\n",
       "      <td>[\"women\"]</td>\n",
       "      <td>The stereotype that this sentence communicates...</td>\n",
       "      <td>text-babbage-001</td>\n",
       "      <td>sbic</td>\n",
       "      <td>sexist</td>\n",
       "      <td>flan-ul2</td>\n",
       "      <td>This sentence communicates the stereotype that...</td>\n",
       "      <td>text-davinci-002</td>\n",
       "      <td>This sentence communicates that the woman in q...</td>\n",
       "      <td>text-curie-001</td>\n",
       "      <td>[\"end up dead\", \"shouldn't speak\", \"women are ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1917 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   post  \\\n",
       "0     What was the hardest part of the holocaust? My...   \n",
       "1     What was the hardest part of the holocaust? My...   \n",
       "2     What was the hardest part of the holocaust? My...   \n",
       "3     What was the hardest part of the holocaust? My...   \n",
       "4     A Cop Told A Suspect To Put His Hands Up, And ...   \n",
       "...                                                 ...   \n",
       "1912  we should not help poor african children\\nthey...   \n",
       "1913  What do you call a woman who speaks their mind...   \n",
       "1914  What do you call a woman who speaks their mind...   \n",
       "1915  What do you call a woman who speaks their mind...   \n",
       "1916  What do you call a woman who speaks their mind...   \n",
       "\n",
       "                             targetMinority  \\\n",
       "0     [\"Holocaust victims\", \"jewish folks\"]   \n",
       "1     [\"Holocaust victims\", \"jewish folks\"]   \n",
       "2     [\"Holocaust victims\", \"jewish folks\"]   \n",
       "3     [\"Holocaust victims\", \"jewish folks\"]   \n",
       "4                           [\"black folks\"]   \n",
       "...                                     ...   \n",
       "1912                      [\"African folks\"]   \n",
       "1913                              [\"women\"]   \n",
       "1914                              [\"women\"]   \n",
       "1915                              [\"women\"]   \n",
       "1916                              [\"women\"]   \n",
       "\n",
       "                                            Generated_1           Model_1  \\\n",
       "0                                     a group of people     flan-t5-small   \n",
       "1     This sentence communicates the stereotype that...  text-davinci-002   \n",
       "2     The sentence communicates that the Holocaust w...    text-curie-001   \n",
       "3                                                  Nazi     flan-t5-large   \n",
       "4     A cop told a suspect to put his hands up, and ...     flan-t5-small   \n",
       "...                                                 ...               ...   \n",
       "1912  The stereotype communicated by this sentence i...    text-curie-001   \n",
       "1913                                    shouldn't speak             human   \n",
       "1914                                        end up dead             human   \n",
       "1915                               women are sex slaves          baseline   \n",
       "1916  The stereotype that this sentence communicates...  text-babbage-001   \n",
       "\n",
       "      Task                                        Generated_2  \\\n",
       "0     sbic  The stereotype communicated by this sentence i...   \n",
       "1     sbic                        trivializes harm to victims   \n",
       "2     sbic  The hardest part of the holocaust was the geno...   \n",
       "3     sbic                                             a dick   \n",
       "4     sbic  This sentence communicates the stereotype that...   \n",
       "...    ...                                                ...   \n",
       "1912  sbic  This sentence communicates the stereotype that...   \n",
       "1913  sbic                                    women are c*nts   \n",
       "1914  sbic  [GROUP] are a group of people who are buried i...   \n",
       "1915  sbic                                              women   \n",
       "1916  sbic                                             sexist   \n",
       "\n",
       "               Model_2                                        Generated_3  \\\n",
       "0     text-davinci-001  I'm sorry, I cannot provide an explanation for...   \n",
       "1                human                         jewish people are unwanted   \n",
       "2     text-babbage-001  The hardest part of the holocaust was the lack...   \n",
       "3         flan-t5-base                                           are dick   \n",
       "4     text-davinci-001                      [GROUP] are a group of people   \n",
       "...                ...                                                ...   \n",
       "1912  text-davinci-003                                 [GROUP] are funny.   \n",
       "1913             human                        a woman who speaks her mind   \n",
       "1914        flan-t5-xl            a woman who speaks their mind is a cunt   \n",
       "1915      flan-t5-base  The stereotype that this sentence communicates...   \n",
       "1916          flan-ul2  This sentence communicates the stereotype that...   \n",
       "\n",
       "               Model_3                                        Generated_4  \\\n",
       "0              chatgpt  Jews are often viewed as victims of the Holocaust   \n",
       "1                human                         jewish people are inferior   \n",
       "2         text-ada-001                                [GROUP] are sexist.   \n",
       "3             baseline                          Jews are a hateful people   \n",
       "4           flan-t5-xl  The sentence \"Cop told suspect to put his hand...   \n",
       "...                ...                                                ...   \n",
       "1912          flan-ul2                                               poor   \n",
       "1913     flan-t5-large  This sentence communicates the stereotype that...   \n",
       "1914       flan-t5-xxl  Women are often seen as being too outspoken or...   \n",
       "1915  text-davinci-001  The speaker is an individual who is passionate...   \n",
       "1916  text-davinci-002  This sentence communicates that the woman in q...   \n",
       "\n",
       "               Model_4                                   targetStereotype  \n",
       "0     text-davinci-003  [\"jewish people are inferior\", \"jewish people ...  \n",
       "1                human  [\"jewish people are inferior\", \"jewish people ...  \n",
       "2             flan-ul2  [\"jewish people are inferior\", \"jewish people ...  \n",
       "3          flan-t5-xxl  [\"jewish people are inferior\", \"jewish people ...  \n",
       "4         text-ada-001  [\"black folks are inferior\", \"black folks dese...  \n",
       "...                ...                                                ...  \n",
       "1912       flan-t5-xxl  [\"african folks don't deserve to eat\", \"africa...  \n",
       "1913           chatgpt  [\"end up dead\", \"shouldn't speak\", \"women are ...  \n",
       "1914  text-davinci-003  [\"end up dead\", \"shouldn't speak\", \"women are ...  \n",
       "1915      text-ada-001  [\"end up dead\", \"shouldn't speak\", \"women are ...  \n",
       "1916    text-curie-001  [\"end up dead\", \"shouldn't speak\", \"women are ...  \n",
       "\n",
       "[1917 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TASK = 'sbic'\n",
    "pd.read_csv(f\"hit/input/comparison_{TASK}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d2c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
